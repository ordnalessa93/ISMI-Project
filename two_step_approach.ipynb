{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from argparse import ArgumentParser\n",
    "from generators_binary import PatchGenerator, PatchSequence\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.utils import multi_gpu_model\n",
    "from networks_binary import (create_initial_model,\n",
    "                      create_second_model,\n",
    "                      create_squeezenet3d_model,\n",
    "                      create_squeezenet3d_model2\n",
    "                     )\n",
    "from skimage.transform import rotate\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# machine learning / deep learning\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "sess = tf.Session(config=config)\n",
    "\n",
    "import keras.backend as K\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sys, os, warnings\n",
    "\n",
    "DATADIR = '/projects/0/ismi2018/FINALPROJECTS/BREAST_3D_ULTRASOUND/shareWithStudents'\n",
    "\n",
    "NETWORKS = {\n",
    "    'initial': create_initial_model,\n",
    "    'second': create_second_model,\n",
    "    'squeezenet3d': create_squeezenet3d_model,\n",
    "    'squeezenet3d2': create_squeezenet3d_model2\n",
    "}\n",
    "\n",
    "LOSS_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "OPTIMIZERS = {\n",
    "    'adam': Adam,\n",
    "    'rmsprop': RMSprop,\n",
    "}\n",
    "\n",
    "\n",
    "class MultiGPUCheckpoint(Callback):\n",
    "\n",
    "    def __init__(self, filename, verbose=0):\n",
    "        super().__init__()\n",
    "        self.filename = filename\n",
    "        self.verbose = verbose\n",
    "        self.val_loss = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if not self.val_loss:\n",
    "            self.model.layers[-2].save(self.filename)\n",
    "        elif logs['val_loss'] < min(self.val_loss):\n",
    "            if self.verbose > 0:\n",
    "                print('Saving to {}'.format(self.filename))\n",
    "            self.model.layers[-2].save(self.filename)\n",
    "        self.val_loss.append(logs['val_loss'])\n",
    "\n",
    "\n",
    "class Accuracies(Callback):\n",
    "\n",
    "    def __init__(self, valid_seq, step = 0):\n",
    "        super().__init__()\n",
    "        self.valid_seq = valid_seq\n",
    "        self.label_accuracies = []\n",
    "        self.step = step\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        \n",
    "        y_pred = self.model.predict_generator(self.valid_seq,\n",
    "                                              workers=4,\n",
    "                                              use_multiprocessing=True)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        y_true = self.valid_seq.get_all_labels()\n",
    "        \n",
    "        if self.step > 0:\n",
    "            y_true = y_true[y_true != 21]\n",
    "            y_true[y_true == 2] = 1\n",
    "            y_true[y_true == 20] = 0\n",
    "        else:\n",
    "            y_true[y_true == 2] = 1\n",
    "            y_true[y_true == 20] = 1\n",
    "            y_true[y_true == 21] = 0\n",
    "        \n",
    "        \n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        ps = cm.diagonal() / cm.sum(axis=1)\n",
    "        self.label_accuracies.append(ps)\n",
    "\n",
    "\n",
    "def create_model(network, optimizer, drop_rate, multi_gpu):\n",
    "    orig_model = NETWORKS[network](drop_rate=drop_rate)\n",
    "    if multi_gpu:\n",
    "        parallel_model = multi_gpu_model(orig_model)\n",
    "        parallel_model.compile(optimizer=optimizer, loss=LOSS_FUNCTION,\n",
    "                               metrics=['accuracy'])\n",
    "    else:\n",
    "        orig_model.compile(optimizer=optimizer, loss=LOSS_FUNCTION,\n",
    "                           metrics=['accuracy'])\n",
    "        parallel_model = None\n",
    "    return orig_model, parallel_model\n",
    "\n",
    "\n",
    "def create_optimizer(name, lr, decay):\n",
    "    return OPTIMIZERS[name](lr=lr, decay=decay)\n",
    "\n",
    "\n",
    "def make_augmentation_func(aug, aug_hflip, aug_vflip, aug_rotate,\n",
    "                           aug_brightness):\n",
    "    if not aug:\n",
    "        return None\n",
    "\n",
    "    def augf(img):\n",
    "        if np.random.random() > aug and aug_hflip:\n",
    "            img = np.flip(img, axis = 1)\n",
    "        if np.random.random() > aug and aug_vflip:\n",
    "            img = np.flip(img, axis = 0)\n",
    "        if np.random.random() > aug and aug_rotate:\n",
    "            tmp = np.squeeze(img)\n",
    "            angle = np.random.uniform(0, aug_rotate)\n",
    "            tmp = rotate(tmp, angle)\n",
    "            img = np.expand_dims(tmp, -1)\n",
    "        if np.random.random() > aug and aug_brightness:\n",
    "            up_delta = 1. - img.max()\n",
    "            down_delta = img.min()\n",
    "            delta = min(up_delta, down_delta)\n",
    "            img = img + np.random.uniform(-delta, delta)\n",
    "        return img[15:55, 15:55, ...]\n",
    "\n",
    "    return augf\n",
    "\n",
    "\n",
    "def make_generators(csv, train_patients, validation_patients, batch_size, step,\n",
    "                    augf):\n",
    "    train_csv = csv.loc[csv['patientID'].isin(train_patients), :]\n",
    "    valid_csv = csv.loc[csv['patientID'].isin(validation_patients), :]\n",
    "\n",
    "    train_gen = PatchGenerator(\n",
    "        input_dir=DATADIR,\n",
    "        dataframe=train_csv,\n",
    "        batch_size=batch_size,\n",
    "        step=step,\n",
    "        augmentation_fn=augf\n",
    "    )\n",
    "\n",
    "    valid_seq = PatchSequence(\n",
    "        input_dir=DATADIR,\n",
    "        dataframe=valid_csv,\n",
    "        batch_size=batch_size,\n",
    "        step=step\n",
    "    )\n",
    "\n",
    "    return train_gen, valid_seq\n",
    "\n",
    "\n",
    "def train_model_1st():\n",
    "    csv = pd.read_csv(os.path.join(DATADIR, 'trainingSet.csv'), dtype=str)\n",
    "\n",
    "    # Create patient K-folder\n",
    "    unique_patients = csv.patientID.unique()\n",
    "    kf = KFold(5, shuffle=True, random_state=42)\n",
    "    folds = kf.split(unique_patients)\n",
    "\n",
    "    # Make augmentation function\n",
    "    augf = make_augmentation_func(0.5, True, True, True, True)\n",
    "    \n",
    "    # -----------------------------------------------------------------------\n",
    "        \n",
    "    accuracies_first = []\n",
    "    # first step training\n",
    "    for i, (train_idxs, val_idxs) in enumerate(folds, start=1):\n",
    "        K.clear_session()\n",
    "        print('Fold {}'.format(i))\n",
    "\n",
    "        train_patients = unique_patients[train_idxs]\n",
    "        val_patients = unique_patients[val_idxs]\n",
    "\n",
    "        train_gen, valid_seq = make_generators(csv,\n",
    "                                               train_patients,\n",
    "                                               val_patients,\n",
    "                                               6,\n",
    "                                               0,\n",
    "                                               augf)\n",
    "        \n",
    "        optimizer = create_optimizer('adam', 1e-5, 1e-6)\n",
    "        orig_net, parallel_net = create_model('squeezenet3d', optimizer,\n",
    "                                              0.5,\n",
    "                                              True)\n",
    "\n",
    "        save_filename = './results_1st/{}_fold_{}.h5'.format('1st-step', i)\n",
    "        \n",
    "        if True:\n",
    "            cp = MultiGPUCheckpoint(save_filename, verbose=1)\n",
    "        else:\n",
    "            cp = ModelCheckpoint(save_filename, save_best_only=True, verbose=1,\n",
    "                                 monitor='val_acc')\n",
    "        ps = Accuracies(valid_seq, 0)\n",
    "\n",
    "        train_model = parallel_net or orig_net\n",
    "                \n",
    "        results = train_model.fit_generator(train_gen,\n",
    "                                            steps_per_epoch=len(train_gen),\n",
    "                                            validation_data=valid_seq,\n",
    "                                            epochs=250,\n",
    "                                            workers=4,\n",
    "                                            use_multiprocessing=True,\n",
    "                                            callbacks=[cp, ps],\n",
    "                                            verbose=1)\n",
    "\n",
    "        h = results.history\n",
    "        plt.figure()\n",
    "        plt.plot(h['loss'])\n",
    "        plt.plot(h['acc'])\n",
    "        plt.plot(h['val_loss'])\n",
    "        plt.plot(h['val_acc'])\n",
    "        plt.legend(['loss', 'acc', 'val_loss', 'val_acc'])\n",
    "        plt.savefig('{}.traininglog.png'.format(save_filename))\n",
    "\n",
    "        y_true = valid_seq.get_all_labels()\n",
    "        y_true[y_true == 2] = 1\n",
    "        y_true[y_true == 20] = 1\n",
    "        y_true[y_true == 21] = 0\n",
    "        best_net = load_model(save_filename)\n",
    "        y_pred = best_net.predict_generator(valid_seq,\n",
    "                                            workers=4,\n",
    "                                            use_multiprocessing=True)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        plt.savefig('{}.confusionmatrix.png'.format(save_filename))\n",
    "\n",
    "        precs = np.array(ps.label_accuracies)\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(precs.shape[1]):\n",
    "            plt.plot(precs[:, i])\n",
    "        plt.legend(['0', '1'])\n",
    "        plt.savefig('{}.accuracies.png'.format(save_filename))\n",
    "\n",
    "        accuracies_first.append(max(h['val_acc']))\n",
    "\n",
    "    with open('{}_score.txt'.format('2step-1'), 'w') as f:\n",
    "        print('Mean accuracy 1st step: {:.4f}\\n'.format(np.mean(accuracies_first)), file=f)\n",
    "        \n",
    "\n",
    "def train_model_2nd():\n",
    "    csv = pd.read_csv(os.path.join(DATADIR, 'trainingSet.csv'), dtype=str)\n",
    "\n",
    "    # Create patient K-folder\n",
    "    unique_patients = csv.patientID.unique()\n",
    "    kf = KFold(5, shuffle=True, random_state=42)\n",
    "    folds = kf.split(unique_patients)\n",
    "\n",
    "    # Make augmentation function\n",
    "    augf = make_augmentation_func(0.5, True, True, True, True)\n",
    "                \n",
    "    # -------------------------------------------------------------------------\n",
    "    accuracies_second = []\n",
    "    # second step training\n",
    "    for i, (train_idxs, val_idxs) in enumerate(folds, start=1):\n",
    "        K.clear_session()\n",
    "        print('Fold {}'.format(i))\n",
    "\n",
    "        train_patients = unique_patients[train_idxs]\n",
    "        val_patients = unique_patients[val_idxs]\n",
    "\n",
    "        train_gen, valid_seq = make_generators(csv,\n",
    "                                               train_patients,\n",
    "                                               val_patients,\n",
    "                                               6,\n",
    "                                               1,\n",
    "                                               augf)\n",
    "        \n",
    "        optimizer = create_optimizer('adam', 1e-5, 1e-6)\n",
    "        orig_net, parallel_net = create_model('squeezenet3d', optimizer,\n",
    "                                              0.5,\n",
    "                                              True)\n",
    "\n",
    "        save_filename = './results_2nd/{}_fold_{}.h5'.format('2nd-step', i)\n",
    "        if True:\n",
    "            cp = MultiGPUCheckpoint(save_filename, verbose=1)\n",
    "        else:\n",
    "            cp = ModelCheckpoint(save_filename, save_best_only=True, verbose=1,\n",
    "                                 monitor='val_acc')\n",
    "        ps = Accuracies(valid_seq, 1)\n",
    "\n",
    "        train_model = parallel_net or orig_net\n",
    "                \n",
    "        results = train_model.fit_generator(train_gen,\n",
    "                                            steps_per_epoch=len(train_gen),\n",
    "                                            validation_data=valid_seq,\n",
    "                                            epochs=250,\n",
    "                                            workers=4,\n",
    "                                            use_multiprocessing=True,\n",
    "                                            callbacks=[cp, ps],\n",
    "                                            verbose=1)\n",
    "\n",
    "        h = results.history\n",
    "        plt.figure()\n",
    "        plt.plot(h['loss'])\n",
    "        plt.plot(h['acc'])\n",
    "        plt.plot(h['val_loss'])\n",
    "        plt.plot(h['val_acc'])\n",
    "        plt.legend(['loss', 'acc', 'val_loss', 'val_acc'])\n",
    "        plt.savefig('{}.traininglog.png'.format(save_filename))\n",
    "\n",
    "        y_true = valid_seq.get_all_labels()\n",
    "        y_true = y_true[y_true != 21]\n",
    "        y_true[y_true == 2] = 1\n",
    "        y_true[y_true == 20] = 0\n",
    "        best_net = load_model(save_filename)\n",
    "        y_pred = best_net.predict_generator(valid_seq,\n",
    "                                            workers=4,\n",
    "                                            use_multiprocessing=True)\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "        plt.figure()\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        plt.savefig('{}.confusionmatrix.png'.format(save_filename))\n",
    "\n",
    "        precs = np.array(ps.label_accuracies)\n",
    "\n",
    "        plt.figure()\n",
    "        for i in range(precs.shape[1]):\n",
    "            plt.plot(precs[:, i])\n",
    "        plt.legend(['0', '1'])\n",
    "        plt.savefig('{}.accuracies.png'.format(save_filename))\n",
    "\n",
    "        accuracies_second.append(max(h['val_acc']))\n",
    "    \n",
    "    with open('{}_score.txt'.format('2step-2'), 'w') as f:\n",
    "        print('Mean accuracy 1st step: {:.4f}\\n'.format(np.mean(accuracies_second)), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "PatchGenerator detected: 239 patch samples.\n",
      "- Cysts: 71 cases\n",
      "- Tumors: 130 cases\n",
      "- Fibroadenoma: 38 cases\n",
      "PatchSequence detected: 59 patch samples.\n",
      "- Cysts: 18 cases\n",
      "- Tumors: 36 cases\n",
      "- Fibroadenoma: 5 cases\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruc0027/.local/lib/python3.5/site-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "39/39 [==============================] - 30s 773ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6924 - val_acc: 0.6949\n",
      "Epoch 2/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6920 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 3/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.6929 - acc: 0.5000 - val_loss: 0.6917 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 4/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.6926 - acc: 0.5000 - val_loss: 0.6902 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 5/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.6923 - acc: 0.5043 - val_loss: 0.6897 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 6/250\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 0.6907 - acc: 0.5214 - val_loss: 0.6873 - val_acc: 0.6610\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 7/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.6897 - acc: 0.5641 - val_loss: 0.6882 - val_acc: 0.7119\n",
      "Epoch 8/250\n",
      "39/39 [==============================] - 23s 580ms/step - loss: 0.6862 - acc: 0.6197 - val_loss: 0.6878 - val_acc: 0.6780\n",
      "Epoch 9/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.6812 - acc: 0.6496 - val_loss: 0.6759 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 10/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.6742 - acc: 0.6325 - val_loss: 0.6864 - val_acc: 0.6102\n",
      "Epoch 11/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.6659 - acc: 0.7094 - val_loss: 0.6737 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 12/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.6557 - acc: 0.6838 - val_loss: 0.6826 - val_acc: 0.5763\n",
      "Epoch 13/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.6382 - acc: 0.7179 - val_loss: 0.6908 - val_acc: 0.5254\n",
      "Epoch 14/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.6320 - acc: 0.6795 - val_loss: 0.6697 - val_acc: 0.5932\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 15/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.6347 - acc: 0.6496 - val_loss: 0.6572 - val_acc: 0.6610\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 16/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.6002 - acc: 0.7051 - val_loss: 0.6554 - val_acc: 0.6610\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 17/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.6240 - acc: 0.6752 - val_loss: 0.6382 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 18/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5981 - acc: 0.7137 - val_loss: 0.6954 - val_acc: 0.4576\n",
      "Epoch 19/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.5800 - acc: 0.7308 - val_loss: 0.6817 - val_acc: 0.4915\n",
      "Epoch 20/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.5838 - acc: 0.7436 - val_loss: 0.6290 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 21/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5720 - acc: 0.7350 - val_loss: 0.6617 - val_acc: 0.5254\n",
      "Epoch 22/250\n",
      "39/39 [==============================] - 23s 580ms/step - loss: 0.5916 - acc: 0.6752 - val_loss: 0.6247 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 23/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.5638 - acc: 0.7137 - val_loss: 0.6605 - val_acc: 0.5085\n",
      "Epoch 24/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.5816 - acc: 0.6966 - val_loss: 0.6197 - val_acc: 0.6780\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 25/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5626 - acc: 0.7308 - val_loss: 0.6529 - val_acc: 0.5085\n",
      "Epoch 26/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.5481 - acc: 0.7179 - val_loss: 0.6154 - val_acc: 0.6780\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 27/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.5670 - acc: 0.6838 - val_loss: 0.6055 - val_acc: 0.7288\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 28/250\n",
      "39/39 [==============================] - 22s 577ms/step - loss: 0.5321 - acc: 0.7308 - val_loss: 0.6333 - val_acc: 0.5424\n",
      "Epoch 29/250\n",
      "39/39 [==============================] - 22s 562ms/step - loss: 0.5448 - acc: 0.7692 - val_loss: 0.6623 - val_acc: 0.5254\n",
      "Epoch 30/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.5243 - acc: 0.7778 - val_loss: 0.5992 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 31/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5317 - acc: 0.7222 - val_loss: 0.6778 - val_acc: 0.5424\n",
      "Epoch 32/250\n",
      "39/39 [==============================] - 23s 581ms/step - loss: 0.5172 - acc: 0.7436 - val_loss: 0.5912 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 33/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.5390 - acc: 0.7308 - val_loss: 0.5930 - val_acc: 0.6610\n",
      "Epoch 34/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5648 - acc: 0.7479 - val_loss: 0.6439 - val_acc: 0.5763\n",
      "Epoch 35/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.5382 - acc: 0.7222 - val_loss: 0.5780 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 36/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.5588 - acc: 0.7393 - val_loss: 0.5939 - val_acc: 0.6271\n",
      "Epoch 37/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.5570 - acc: 0.7179 - val_loss: 0.5748 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 38/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.5530 - acc: 0.7650 - val_loss: 0.5641 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 39/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.5400 - acc: 0.7308 - val_loss: 0.5720 - val_acc: 0.6780\n",
      "Epoch 40/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.5108 - acc: 0.7607 - val_loss: 0.5767 - val_acc: 0.6780\n",
      "Epoch 41/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.5713 - acc: 0.6838 - val_loss: 0.6264 - val_acc: 0.6271\n",
      "Epoch 42/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.4942 - acc: 0.7991 - val_loss: 0.5529 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 43/250\n",
      "39/39 [==============================] - 22s 577ms/step - loss: 0.5247 - acc: 0.7479 - val_loss: 0.5857 - val_acc: 0.6271\n",
      "Epoch 44/250\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.5532 - acc: 0.7222 - val_loss: 0.5593 - val_acc: 0.6780\n",
      "Epoch 45/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.5282 - acc: 0.7564 - val_loss: 0.5406 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 46/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4814 - acc: 0.7735 - val_loss: 0.5864 - val_acc: 0.6441\n",
      "Epoch 47/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4892 - acc: 0.7479 - val_loss: 0.5852 - val_acc: 0.6271\n",
      "Epoch 48/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5545 - acc: 0.7308 - val_loss: 0.5363 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 49/250\n",
      "39/39 [==============================] - 22s 563ms/step - loss: 0.4684 - acc: 0.8034 - val_loss: 0.5535 - val_acc: 0.6949\n",
      "Epoch 50/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.5100 - acc: 0.7650 - val_loss: 0.5914 - val_acc: 0.6610\n",
      "Epoch 51/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.5757 - acc: 0.7393 - val_loss: 0.5941 - val_acc: 0.6441\n",
      "Epoch 52/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.5332 - acc: 0.7735 - val_loss: 0.5242 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 53/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4946 - acc: 0.7607 - val_loss: 0.5396 - val_acc: 0.7458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.5527 - acc: 0.7179 - val_loss: 0.5653 - val_acc: 0.7458\n",
      "Epoch 55/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.4703 - acc: 0.7821 - val_loss: 0.6180 - val_acc: 0.6102\n",
      "Epoch 56/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.5366 - acc: 0.7607 - val_loss: 0.5291 - val_acc: 0.7458\n",
      "Epoch 57/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5112 - acc: 0.7479 - val_loss: 0.5176 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 58/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4988 - acc: 0.7521 - val_loss: 0.5170 - val_acc: 0.6949\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 59/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4959 - acc: 0.7949 - val_loss: 0.5190 - val_acc: 0.7458\n",
      "Epoch 60/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4978 - acc: 0.7778 - val_loss: 0.5706 - val_acc: 0.6949\n",
      "Epoch 61/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.5439 - acc: 0.7222 - val_loss: 0.5811 - val_acc: 0.6610\n",
      "Epoch 62/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.5090 - acc: 0.7863 - val_loss: 0.5465 - val_acc: 0.7627\n",
      "Epoch 63/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4626 - acc: 0.8034 - val_loss: 0.5201 - val_acc: 0.7797\n",
      "Epoch 64/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4761 - acc: 0.7692 - val_loss: 0.5453 - val_acc: 0.7627\n",
      "Epoch 65/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.5115 - acc: 0.7564 - val_loss: 0.5350 - val_acc: 0.7797\n",
      "Epoch 66/250\n",
      "39/39 [==============================] - 23s 581ms/step - loss: 0.4578 - acc: 0.8077 - val_loss: 0.4843 - val_acc: 0.7119\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 67/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.5139 - acc: 0.7778 - val_loss: 0.4862 - val_acc: 0.7627\n",
      "Epoch 68/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4713 - acc: 0.7821 - val_loss: 0.4878 - val_acc: 0.7797\n",
      "Epoch 69/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.5377 - acc: 0.7521 - val_loss: 0.5005 - val_acc: 0.7627\n",
      "Epoch 70/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.5314 - acc: 0.7094 - val_loss: 0.5239 - val_acc: 0.7966\n",
      "Epoch 71/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4823 - acc: 0.7692 - val_loss: 0.5179 - val_acc: 0.7627\n",
      "Epoch 72/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.5195 - acc: 0.7393 - val_loss: 0.4927 - val_acc: 0.7288\n",
      "Epoch 73/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.5246 - acc: 0.7265 - val_loss: 0.5385 - val_acc: 0.7797\n",
      "Epoch 74/250\n",
      "39/39 [==============================] - 22s 577ms/step - loss: 0.4751 - acc: 0.7906 - val_loss: 0.5052 - val_acc: 0.7797\n",
      "Epoch 75/250\n",
      "39/39 [==============================] - 22s 563ms/step - loss: 0.4973 - acc: 0.7607 - val_loss: 0.5191 - val_acc: 0.7966\n",
      "Epoch 76/250\n",
      "39/39 [==============================] - 22s 564ms/step - loss: 0.4763 - acc: 0.7991 - val_loss: 0.5483 - val_acc: 0.7458\n",
      "Epoch 77/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4773 - acc: 0.7949 - val_loss: 0.4845 - val_acc: 0.7797\n",
      "Epoch 78/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4804 - acc: 0.7607 - val_loss: 0.5286 - val_acc: 0.8136\n",
      "Epoch 79/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4744 - acc: 0.7821 - val_loss: 0.5316 - val_acc: 0.7797\n",
      "Epoch 80/250\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 0.4666 - acc: 0.8077 - val_loss: 0.5034 - val_acc: 0.7797\n",
      "Epoch 81/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5479 - acc: 0.7222 - val_loss: 0.6017 - val_acc: 0.5593\n",
      "Epoch 82/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4334 - acc: 0.8162 - val_loss: 0.5494 - val_acc: 0.7288\n",
      "Epoch 83/250\n",
      "39/39 [==============================] - 23s 581ms/step - loss: 0.4635 - acc: 0.7821 - val_loss: 0.4917 - val_acc: 0.7627\n",
      "Epoch 84/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.5079 - acc: 0.7692 - val_loss: 0.6561 - val_acc: 0.5424\n",
      "Epoch 85/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.4769 - acc: 0.7991 - val_loss: 0.5075 - val_acc: 0.8305\n",
      "Epoch 86/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4685 - acc: 0.7863 - val_loss: 0.5104 - val_acc: 0.8305\n",
      "Epoch 87/250\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.5015 - acc: 0.7393 - val_loss: 0.5495 - val_acc: 0.7288\n",
      "Epoch 88/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4682 - acc: 0.7821 - val_loss: 0.4771 - val_acc: 0.8136\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 89/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.5220 - acc: 0.7564 - val_loss: 0.4631 - val_acc: 0.7288\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 90/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5108 - acc: 0.7735 - val_loss: 0.5125 - val_acc: 0.7966\n",
      "Epoch 91/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4874 - acc: 0.7735 - val_loss: 0.4929 - val_acc: 0.8136\n",
      "Epoch 92/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4660 - acc: 0.7906 - val_loss: 0.4636 - val_acc: 0.7288\n",
      "Epoch 93/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5206 - acc: 0.7436 - val_loss: 0.5803 - val_acc: 0.6441\n",
      "Epoch 94/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4749 - acc: 0.7692 - val_loss: 0.4633 - val_acc: 0.7119\n",
      "Epoch 95/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.5230 - acc: 0.7607 - val_loss: 0.4664 - val_acc: 0.8136\n",
      "Epoch 96/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4385 - acc: 0.8034 - val_loss: 0.5168 - val_acc: 0.7966\n",
      "Epoch 97/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4598 - acc: 0.7991 - val_loss: 0.4919 - val_acc: 0.8305\n",
      "Epoch 98/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4281 - acc: 0.8077 - val_loss: 0.4841 - val_acc: 0.8136\n",
      "Epoch 99/250\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 0.4640 - acc: 0.7949 - val_loss: 0.4541 - val_acc: 0.7458\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 100/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.4700 - acc: 0.7692 - val_loss: 0.5838 - val_acc: 0.6102\n",
      "Epoch 101/250\n",
      "39/39 [==============================] - 23s 580ms/step - loss: 0.5049 - acc: 0.7564 - val_loss: 0.4916 - val_acc: 0.8136\n",
      "Epoch 102/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.5517 - acc: 0.7179 - val_loss: 0.4578 - val_acc: 0.7966\n",
      "Epoch 103/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4103 - acc: 0.8205 - val_loss: 0.4902 - val_acc: 0.8305\n",
      "Epoch 104/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4394 - acc: 0.8162 - val_loss: 0.4779 - val_acc: 0.8136\n",
      "Epoch 105/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4905 - acc: 0.7436 - val_loss: 0.4736 - val_acc: 0.7966\n",
      "Epoch 106/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4510 - acc: 0.8034 - val_loss: 0.5784 - val_acc: 0.6102\n",
      "Epoch 107/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4584 - acc: 0.7991 - val_loss: 0.4822 - val_acc: 0.8305\n",
      "Epoch 108/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4789 - acc: 0.7863 - val_loss: 0.4741 - val_acc: 0.7966\n",
      "Epoch 109/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4391 - acc: 0.8077 - val_loss: 0.4767 - val_acc: 0.8644\n",
      "Epoch 110/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4996 - acc: 0.7821 - val_loss: 0.4451 - val_acc: 0.8136\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 111/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4995 - acc: 0.7650 - val_loss: 0.5132 - val_acc: 0.7797\n",
      "Epoch 112/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.4850 - acc: 0.7821 - val_loss: 0.4653 - val_acc: 0.8475\n",
      "Epoch 113/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4480 - acc: 0.7735 - val_loss: 0.4365 - val_acc: 0.7627\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 114/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4162 - acc: 0.8333 - val_loss: 0.4407 - val_acc: 0.8136\n",
      "Epoch 115/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.5010 - acc: 0.7607 - val_loss: 0.5119 - val_acc: 0.7458\n",
      "Epoch 116/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.5285 - acc: 0.7521 - val_loss: 0.4749 - val_acc: 0.8475\n",
      "Epoch 117/250\n",
      "39/39 [==============================] - 23s 583ms/step - loss: 0.4826 - acc: 0.7650 - val_loss: 0.4630 - val_acc: 0.8305\n",
      "Epoch 118/250\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.4435 - acc: 0.7949 - val_loss: 0.5121 - val_acc: 0.7458\n",
      "Epoch 119/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.5208 - acc: 0.7564 - val_loss: 0.4515 - val_acc: 0.7119\n",
      "Epoch 120/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4084 - acc: 0.8291 - val_loss: 0.4479 - val_acc: 0.7966\n",
      "Epoch 121/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4411 - acc: 0.7991 - val_loss: 0.5397 - val_acc: 0.6780\n",
      "Epoch 122/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4775 - acc: 0.7692 - val_loss: 0.4610 - val_acc: 0.8475\n",
      "Epoch 123/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4953 - acc: 0.7906 - val_loss: 0.5051 - val_acc: 0.7458\n",
      "Epoch 124/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4842 - acc: 0.7863 - val_loss: 0.6019 - val_acc: 0.6102\n",
      "Epoch 125/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4706 - acc: 0.7906 - val_loss: 0.4338 - val_acc: 0.8136\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 126/250\n",
      "39/39 [==============================] - 22s 561ms/step - loss: 0.5038 - acc: 0.7906 - val_loss: 0.5539 - val_acc: 0.6441\n",
      "Epoch 127/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4804 - acc: 0.7906 - val_loss: 0.5070 - val_acc: 0.7288\n",
      "Epoch 128/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4835 - acc: 0.7650 - val_loss: 0.4574 - val_acc: 0.8814\n",
      "Epoch 129/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4657 - acc: 0.8162 - val_loss: 0.4773 - val_acc: 0.7966\n",
      "Epoch 130/250\n",
      "39/39 [==============================] - 22s 564ms/step - loss: 0.4924 - acc: 0.7778 - val_loss: 0.4610 - val_acc: 0.8644\n",
      "Epoch 131/250\n",
      "39/39 [==============================] - 22s 560ms/step - loss: 0.4944 - acc: 0.7778 - val_loss: 0.5001 - val_acc: 0.7627\n",
      "Epoch 132/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4768 - acc: 0.8077 - val_loss: 0.4674 - val_acc: 0.8305\n",
      "Epoch 133/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4684 - acc: 0.7863 - val_loss: 0.5159 - val_acc: 0.7458\n",
      "Epoch 134/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4545 - acc: 0.7778 - val_loss: 0.5197 - val_acc: 0.7458\n",
      "Epoch 135/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4970 - acc: 0.7650 - val_loss: 0.4260 - val_acc: 0.8136\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 136/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4797 - acc: 0.7991 - val_loss: 0.4934 - val_acc: 0.7797\n",
      "Epoch 137/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4739 - acc: 0.7607 - val_loss: 0.4537 - val_acc: 0.8814\n",
      "Epoch 138/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4575 - acc: 0.7863 - val_loss: 0.4673 - val_acc: 0.8644\n",
      "Epoch 139/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4416 - acc: 0.7991 - val_loss: 0.4824 - val_acc: 0.7966\n",
      "Epoch 140/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4755 - acc: 0.7564 - val_loss: 0.4296 - val_acc: 0.8305\n",
      "Epoch 141/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4427 - acc: 0.8034 - val_loss: 0.4404 - val_acc: 0.8475\n",
      "Epoch 142/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4809 - acc: 0.7479 - val_loss: 0.4603 - val_acc: 0.8136\n",
      "Epoch 143/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4199 - acc: 0.8120 - val_loss: 0.4424 - val_acc: 0.8305\n",
      "Epoch 144/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4563 - acc: 0.8162 - val_loss: 0.4339 - val_acc: 0.8136\n",
      "Epoch 145/250\n",
      "39/39 [==============================] - 23s 586ms/step - loss: 0.5028 - acc: 0.7821 - val_loss: 0.4850 - val_acc: 0.7966\n",
      "Epoch 146/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4534 - acc: 0.8034 - val_loss: 0.4650 - val_acc: 0.8136\n",
      "Epoch 147/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4268 - acc: 0.8120 - val_loss: 0.4690 - val_acc: 0.7966\n",
      "Epoch 148/250\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 0.4944 - acc: 0.7650 - val_loss: 0.4227 - val_acc: 0.8305\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 149/250\n",
      "39/39 [==============================] - 22s 577ms/step - loss: 0.4576 - acc: 0.8034 - val_loss: 0.4677 - val_acc: 0.7797\n",
      "Epoch 150/250\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 0.5010 - acc: 0.7863 - val_loss: 0.5234 - val_acc: 0.7288\n",
      "Epoch 151/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4634 - acc: 0.7949 - val_loss: 0.4701 - val_acc: 0.7797\n",
      "Epoch 152/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4331 - acc: 0.8291 - val_loss: 0.4676 - val_acc: 0.7797\n",
      "Epoch 153/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4562 - acc: 0.7863 - val_loss: 0.4982 - val_acc: 0.7288\n",
      "Epoch 154/250\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.4395 - acc: 0.7607 - val_loss: 0.4218 - val_acc: 0.8475\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 155/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4473 - acc: 0.8077 - val_loss: 0.4420 - val_acc: 0.8644\n",
      "Epoch 156/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4329 - acc: 0.8120 - val_loss: 0.4688 - val_acc: 0.7797\n",
      "Epoch 157/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4291 - acc: 0.7991 - val_loss: 0.4000 - val_acc: 0.8305\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 158/250\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.3768 - acc: 0.8376 - val_loss: 0.5644 - val_acc: 0.6441\n",
      "Epoch 159/250\n",
      "39/39 [==============================] - 22s 563ms/step - loss: 0.4269 - acc: 0.7991 - val_loss: 0.4739 - val_acc: 0.8305\n",
      "Epoch 160/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4289 - acc: 0.8162 - val_loss: 0.4800 - val_acc: 0.7797\n",
      "Epoch 161/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4880 - acc: 0.7350 - val_loss: 0.4638 - val_acc: 0.8305\n",
      "Epoch 162/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4472 - acc: 0.8120 - val_loss: 0.4462 - val_acc: 0.8475\n",
      "Epoch 163/250\n",
      "39/39 [==============================] - 23s 580ms/step - loss: 0.4834 - acc: 0.7564 - val_loss: 0.5701 - val_acc: 0.6441\n",
      "Epoch 164/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4519 - acc: 0.7991 - val_loss: 0.4016 - val_acc: 0.8136\n",
      "Epoch 165/250\n",
      "39/39 [==============================] - 22s 577ms/step - loss: 0.4376 - acc: 0.8034 - val_loss: 0.4535 - val_acc: 0.8305\n",
      "Epoch 166/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.4502 - acc: 0.7821 - val_loss: 0.4615 - val_acc: 0.8475\n",
      "Epoch 167/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4662 - acc: 0.7863 - val_loss: 0.4300 - val_acc: 0.8475\n",
      "Epoch 168/250\n",
      "39/39 [==============================] - 22s 565ms/step - loss: 0.4752 - acc: 0.7906 - val_loss: 0.4028 - val_acc: 0.8305\n",
      "Epoch 169/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4156 - acc: 0.8248 - val_loss: 0.4276 - val_acc: 0.8814\n",
      "Epoch 170/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4510 - acc: 0.8034 - val_loss: 0.4598 - val_acc: 0.8475\n",
      "Epoch 171/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4145 - acc: 0.8205 - val_loss: 0.4691 - val_acc: 0.7797\n",
      "Epoch 172/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4402 - acc: 0.8248 - val_loss: 0.4377 - val_acc: 0.8644\n",
      "Epoch 173/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.5053 - acc: 0.7735 - val_loss: 0.4330 - val_acc: 0.8814\n",
      "Epoch 174/250\n",
      "39/39 [==============================] - 23s 581ms/step - loss: 0.4796 - acc: 0.7479 - val_loss: 0.4435 - val_acc: 0.8814\n",
      "Epoch 175/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4316 - acc: 0.8077 - val_loss: 0.4529 - val_acc: 0.8644\n",
      "Epoch 176/250\n",
      "39/39 [==============================] - 22s 560ms/step - loss: 0.4102 - acc: 0.8376 - val_loss: 0.4197 - val_acc: 0.8814\n",
      "Epoch 177/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4495 - acc: 0.8077 - val_loss: 0.3877 - val_acc: 0.8305\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 178/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.4562 - acc: 0.7692 - val_loss: 0.4408 - val_acc: 0.8475\n",
      "Epoch 179/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4349 - acc: 0.8291 - val_loss: 0.5730 - val_acc: 0.6441\n",
      "Epoch 180/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.5195 - acc: 0.7479 - val_loss: 0.4192 - val_acc: 0.8814\n",
      "Epoch 181/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4359 - acc: 0.8291 - val_loss: 0.4942 - val_acc: 0.7458\n",
      "Epoch 182/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4502 - acc: 0.8034 - val_loss: 0.3914 - val_acc: 0.8136\n",
      "Epoch 183/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4675 - acc: 0.7735 - val_loss: 0.4325 - val_acc: 0.8814\n",
      "Epoch 184/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4175 - acc: 0.8034 - val_loss: 0.4345 - val_acc: 0.8644\n",
      "Epoch 185/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.5076 - acc: 0.7692 - val_loss: 0.4644 - val_acc: 0.8644\n",
      "Epoch 186/250\n",
      "39/39 [==============================] - 22s 564ms/step - loss: 0.4818 - acc: 0.7650 - val_loss: 0.3973 - val_acc: 0.8305\n",
      "Epoch 187/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4423 - acc: 0.8077 - val_loss: 0.4056 - val_acc: 0.8305\n",
      "Epoch 188/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.5085 - acc: 0.7607 - val_loss: 0.5687 - val_acc: 0.6441\n",
      "Epoch 189/250\n",
      "39/39 [==============================] - 23s 580ms/step - loss: 0.4646 - acc: 0.7821 - val_loss: 0.4910 - val_acc: 0.7288\n",
      "Epoch 190/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4285 - acc: 0.7991 - val_loss: 0.4846 - val_acc: 0.7458\n",
      "Epoch 191/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4214 - acc: 0.8205 - val_loss: 0.3955 - val_acc: 0.8814\n",
      "Epoch 192/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4761 - acc: 0.7692 - val_loss: 0.4706 - val_acc: 0.7458\n",
      "Epoch 193/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4319 - acc: 0.8205 - val_loss: 0.4719 - val_acc: 0.7458\n",
      "Epoch 194/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4836 - acc: 0.7692 - val_loss: 0.4083 - val_acc: 0.8814\n",
      "Epoch 195/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4647 - acc: 0.7692 - val_loss: 0.3726 - val_acc: 0.8305\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 196/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4219 - acc: 0.8205 - val_loss: 0.5186 - val_acc: 0.6610\n",
      "Epoch 197/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4115 - acc: 0.8462 - val_loss: 0.4295 - val_acc: 0.8475\n",
      "Epoch 198/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4260 - acc: 0.8291 - val_loss: 0.4656 - val_acc: 0.7966\n",
      "Epoch 199/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.3635 - acc: 0.8675 - val_loss: 0.3705 - val_acc: 0.8644\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 200/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4567 - acc: 0.7778 - val_loss: 0.3873 - val_acc: 0.8814\n",
      "Epoch 201/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.3848 - acc: 0.8462 - val_loss: 0.4819 - val_acc: 0.7627\n",
      "Epoch 202/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4540 - acc: 0.7650 - val_loss: 0.4275 - val_acc: 0.8475\n",
      "Epoch 203/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.3831 - acc: 0.8419 - val_loss: 0.4516 - val_acc: 0.7966\n",
      "Epoch 204/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4634 - acc: 0.7863 - val_loss: 0.3774 - val_acc: 0.8644\n",
      "Epoch 205/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4693 - acc: 0.7821 - val_loss: 0.3782 - val_acc: 0.8305\n",
      "Epoch 206/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4329 - acc: 0.8162 - val_loss: 0.4142 - val_acc: 0.8644\n",
      "Epoch 207/250\n",
      "39/39 [==============================] - 23s 585ms/step - loss: 0.4244 - acc: 0.8205 - val_loss: 0.4304 - val_acc: 0.8644\n",
      "Epoch 208/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.4416 - acc: 0.7949 - val_loss: 0.4881 - val_acc: 0.7458\n",
      "Epoch 209/250\n",
      "39/39 [==============================] - 23s 588ms/step - loss: 0.3871 - acc: 0.8333 - val_loss: 0.3725 - val_acc: 0.8644\n",
      "Epoch 210/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4442 - acc: 0.8162 - val_loss: 0.5417 - val_acc: 0.6780\n",
      "Epoch 211/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4885 - acc: 0.7650 - val_loss: 0.4448 - val_acc: 0.7627\n",
      "Epoch 212/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4601 - acc: 0.7607 - val_loss: 0.4463 - val_acc: 0.7627\n",
      "Epoch 213/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4785 - acc: 0.7735 - val_loss: 0.5341 - val_acc: 0.6610\n",
      "Epoch 214/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4165 - acc: 0.8077 - val_loss: 0.3742 - val_acc: 0.8644\n",
      "Epoch 215/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4007 - acc: 0.8120 - val_loss: 0.4889 - val_acc: 0.7458\n",
      "Epoch 216/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4377 - acc: 0.8077 - val_loss: 0.4252 - val_acc: 0.8644\n",
      "Epoch 217/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.4143 - acc: 0.8120 - val_loss: 0.4036 - val_acc: 0.8644\n",
      "Epoch 218/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4580 - acc: 0.7949 - val_loss: 0.3725 - val_acc: 0.8644\n",
      "Epoch 219/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4246 - acc: 0.7991 - val_loss: 0.5556 - val_acc: 0.6441\n",
      "Epoch 220/250\n",
      "39/39 [==============================] - 23s 580ms/step - loss: 0.4831 - acc: 0.7350 - val_loss: 0.4015 - val_acc: 0.8814\n",
      "Epoch 221/250\n",
      "39/39 [==============================] - 23s 581ms/step - loss: 0.4361 - acc: 0.8077 - val_loss: 0.5114 - val_acc: 0.6949\n",
      "Epoch 222/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4671 - acc: 0.7949 - val_loss: 0.4120 - val_acc: 0.8475\n",
      "Epoch 223/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4672 - acc: 0.7735 - val_loss: 0.3849 - val_acc: 0.8644\n",
      "Epoch 224/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4098 - acc: 0.8376 - val_loss: 0.4251 - val_acc: 0.8305\n",
      "Epoch 225/250\n",
      "39/39 [==============================] - 22s 562ms/step - loss: 0.4130 - acc: 0.8248 - val_loss: 0.4280 - val_acc: 0.8305\n",
      "Epoch 226/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4147 - acc: 0.8120 - val_loss: 0.4221 - val_acc: 0.8644\n",
      "Epoch 227/250\n",
      "39/39 [==============================] - 23s 578ms/step - loss: 0.4536 - acc: 0.8205 - val_loss: 0.5227 - val_acc: 0.6780\n",
      "Epoch 228/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4311 - acc: 0.7991 - val_loss: 0.4344 - val_acc: 0.8644\n",
      "Epoch 229/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.3883 - acc: 0.8291 - val_loss: 0.4500 - val_acc: 0.8305\n",
      "Epoch 230/250\n",
      "39/39 [==============================] - 22s 564ms/step - loss: 0.4138 - acc: 0.8120 - val_loss: 0.3630 - val_acc: 0.8475\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 231/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4065 - acc: 0.8162 - val_loss: 0.5054 - val_acc: 0.7119\n",
      "Epoch 232/250\n",
      "39/39 [==============================] - 22s 567ms/step - loss: 0.3506 - acc: 0.8462 - val_loss: 0.4196 - val_acc: 0.8644\n",
      "Epoch 233/250\n",
      "39/39 [==============================] - 23s 584ms/step - loss: 0.4095 - acc: 0.8462 - val_loss: 0.3621 - val_acc: 0.8814\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 234/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4599 - acc: 0.8162 - val_loss: 0.4209 - val_acc: 0.8644\n",
      "Epoch 235/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.3769 - acc: 0.8333 - val_loss: 0.3618 - val_acc: 0.8983\n",
      "Saving to ./results_1st/1st-step_fold_1.h5\n",
      "Epoch 236/250\n",
      "39/39 [==============================] - 22s 566ms/step - loss: 0.4406 - acc: 0.7735 - val_loss: 0.3869 - val_acc: 0.8644\n",
      "Epoch 237/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4043 - acc: 0.8333 - val_loss: 0.4524 - val_acc: 0.8136\n",
      "Epoch 238/250\n",
      "39/39 [==============================] - 22s 571ms/step - loss: 0.4295 - acc: 0.8162 - val_loss: 0.3943 - val_acc: 0.8814\n",
      "Epoch 239/250\n",
      "39/39 [==============================] - 23s 577ms/step - loss: 0.4158 - acc: 0.8333 - val_loss: 0.4436 - val_acc: 0.8644\n",
      "Epoch 240/250\n",
      "39/39 [==============================] - 22s 574ms/step - loss: 0.4281 - acc: 0.8077 - val_loss: 0.5199 - val_acc: 0.7119\n",
      "Epoch 241/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4544 - acc: 0.7778 - val_loss: 0.3919 - val_acc: 0.8983\n",
      "Epoch 242/250\n",
      "39/39 [==============================] - 22s 569ms/step - loss: 0.4080 - acc: 0.7949 - val_loss: 0.5521 - val_acc: 0.6780\n",
      "Epoch 243/250\n",
      "39/39 [==============================] - 22s 568ms/step - loss: 0.4238 - acc: 0.8162 - val_loss: 0.5522 - val_acc: 0.6610\n",
      "Epoch 244/250\n",
      "39/39 [==============================] - 22s 570ms/step - loss: 0.4121 - acc: 0.8162 - val_loss: 0.4021 - val_acc: 0.8814\n",
      "Epoch 245/250\n",
      "39/39 [==============================] - 22s 576ms/step - loss: 0.4490 - acc: 0.7906 - val_loss: 0.3712 - val_acc: 0.8644\n",
      "Epoch 246/250\n",
      "39/39 [==============================] - 22s 575ms/step - loss: 0.4423 - acc: 0.7607 - val_loss: 0.4812 - val_acc: 0.7627\n",
      "Epoch 247/250\n",
      "39/39 [==============================] - 22s 573ms/step - loss: 0.4354 - acc: 0.8077 - val_loss: 0.5634 - val_acc: 0.6610\n",
      "Epoch 248/250\n",
      "39/39 [==============================] - 22s 572ms/step - loss: 0.4514 - acc: 0.8077 - val_loss: 0.4295 - val_acc: 0.8305\n",
      "Epoch 249/250\n",
      "39/39 [==============================] - 23s 579ms/step - loss: 0.4330 - acc: 0.7949 - val_loss: 0.4181 - val_acc: 0.8644\n",
      "Epoch 250/250\n",
      "39/39 [==============================] - 23s 582ms/step - loss: 0.4322 - acc: 0.8205 - val_loss: 0.3950 - val_acc: 0.8814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruc0027/.local/lib/python3.5/site-packages/keras/models.py:255: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2\n",
      "PatchGenerator detected: 241 patch samples.\n",
      "- Cysts: 73 cases\n",
      "- Tumors: 136 cases\n",
      "- Fibroadenoma: 32 cases\n",
      "PatchSequence detected: 57 patch samples.\n",
      "- Cysts: 16 cases\n",
      "- Tumors: 30 cases\n",
      "- Fibroadenoma: 11 cases\n",
      "Epoch 1/250\n",
      "40/40 [==============================] - 30s 756ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.2807\n",
      "Epoch 2/250\n",
      "40/40 [==============================] - 22s 547ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6933 - val_acc: 0.2807\n",
      "Epoch 3/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.6931 - acc: 0.5000 - val_loss: 0.6936 - val_acc: 0.2807\n",
      "Epoch 4/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6939 - val_acc: 0.2807\n",
      "Epoch 5/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.6930 - acc: 0.5000 - val_loss: 0.6943 - val_acc: 0.2807\n",
      "Epoch 6/250\n",
      "40/40 [==============================] - 23s 572ms/step - loss: 0.6928 - acc: 0.5000 - val_loss: 0.6940 - val_acc: 0.2807\n",
      "Epoch 7/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.6923 - acc: 0.5250 - val_loss: 0.6939 - val_acc: 0.3684\n",
      "Epoch 8/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.6913 - acc: 0.6208 - val_loss: 0.6941 - val_acc: 0.3860\n",
      "Epoch 9/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.6900 - acc: 0.6208 - val_loss: 0.6949 - val_acc: 0.3684\n",
      "Epoch 10/250\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.6865 - acc: 0.7042 - val_loss: 0.6850 - val_acc: 0.7018\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 11/250\n",
      "40/40 [==============================] - 23s 569ms/step - loss: 0.6812 - acc: 0.6792 - val_loss: 0.6747 - val_acc: 0.7895\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 12/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.6741 - acc: 0.6667 - val_loss: 0.6705 - val_acc: 0.7018\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 13/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.6548 - acc: 0.7375 - val_loss: 0.6367 - val_acc: 0.8246\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 14/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.6421 - acc: 0.7125 - val_loss: 0.6095 - val_acc: 0.8596\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 15/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.6325 - acc: 0.7000 - val_loss: 0.6395 - val_acc: 0.6842\n",
      "Epoch 16/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.5990 - acc: 0.7250 - val_loss: 0.5834 - val_acc: 0.7719\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 17/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.6048 - acc: 0.6625 - val_loss: 0.6166 - val_acc: 0.6842\n",
      "Epoch 18/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.5772 - acc: 0.7083 - val_loss: 0.5363 - val_acc: 0.8070\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 19/250\n",
      "40/40 [==============================] - 22s 547ms/step - loss: 0.5956 - acc: 0.6792 - val_loss: 0.5134 - val_acc: 0.8772\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 20/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.5453 - acc: 0.7792 - val_loss: 0.5791 - val_acc: 0.7018\n",
      "Epoch 21/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.5394 - acc: 0.7542 - val_loss: 0.5409 - val_acc: 0.7719\n",
      "Epoch 22/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.5579 - acc: 0.7208 - val_loss: 0.5109 - val_acc: 0.8070\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 23/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.5763 - acc: 0.7083 - val_loss: 0.5382 - val_acc: 0.7193\n",
      "Epoch 24/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.5141 - acc: 0.7458 - val_loss: 0.4641 - val_acc: 0.8596\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 25/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.5331 - acc: 0.7208 - val_loss: 0.5974 - val_acc: 0.7018\n",
      "Epoch 26/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.5324 - acc: 0.7542 - val_loss: 0.5039 - val_acc: 0.7895\n",
      "Epoch 27/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.5310 - acc: 0.7250 - val_loss: 0.5162 - val_acc: 0.7895\n",
      "Epoch 28/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.5242 - acc: 0.7458 - val_loss: 0.4931 - val_acc: 0.7895\n",
      "Epoch 29/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.5112 - acc: 0.7542 - val_loss: 0.4664 - val_acc: 0.7895\n",
      "Epoch 30/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.5226 - acc: 0.7625 - val_loss: 0.4865 - val_acc: 0.7895\n",
      "Epoch 31/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.5106 - acc: 0.7375 - val_loss: 0.5103 - val_acc: 0.7895\n",
      "Epoch 32/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.5283 - acc: 0.7333 - val_loss: 0.4758 - val_acc: 0.7895\n",
      "Epoch 33/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.5118 - acc: 0.7625 - val_loss: 0.4189 - val_acc: 0.8596\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 34/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.5202 - acc: 0.7292 - val_loss: 0.4890 - val_acc: 0.7895\n",
      "Epoch 35/250\n",
      "40/40 [==============================] - 23s 568ms/step - loss: 0.5128 - acc: 0.7583 - val_loss: 0.5230 - val_acc: 0.7368\n",
      "Epoch 36/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.5045 - acc: 0.7667 - val_loss: 0.4448 - val_acc: 0.8421\n",
      "Epoch 37/250\n",
      "40/40 [==============================] - 22s 544ms/step - loss: 0.5076 - acc: 0.7667 - val_loss: 0.5014 - val_acc: 0.7719\n",
      "Epoch 38/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.4550 - acc: 0.7958 - val_loss: 0.5088 - val_acc: 0.7719\n",
      "Epoch 39/250\n",
      "40/40 [==============================] - 23s 568ms/step - loss: 0.4613 - acc: 0.7708 - val_loss: 0.4127 - val_acc: 0.8421\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 40/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.5204 - acc: 0.7375 - val_loss: 0.5024 - val_acc: 0.7719\n",
      "Epoch 41/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4973 - acc: 0.7292 - val_loss: 0.4379 - val_acc: 0.8421\n",
      "Epoch 42/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.4974 - acc: 0.7708 - val_loss: 0.5353 - val_acc: 0.7018\n",
      "Epoch 43/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.5217 - acc: 0.7542 - val_loss: 0.5043 - val_acc: 0.7544\n",
      "Epoch 44/250\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.5145 - acc: 0.7667 - val_loss: 0.5167 - val_acc: 0.7368\n",
      "Epoch 45/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.5051 - acc: 0.7458 - val_loss: 0.5756 - val_acc: 0.7193\n",
      "Epoch 46/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4961 - acc: 0.7708 - val_loss: 0.4285 - val_acc: 0.8596\n",
      "Epoch 47/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.5303 - acc: 0.7292 - val_loss: 0.4787 - val_acc: 0.7895\n",
      "Epoch 48/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.4944 - acc: 0.7708 - val_loss: 0.4392 - val_acc: 0.8246\n",
      "Epoch 49/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.4278 - acc: 0.8250 - val_loss: 0.4768 - val_acc: 0.7895\n",
      "Epoch 50/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.5319 - acc: 0.7292 - val_loss: 0.4992 - val_acc: 0.7719\n",
      "Epoch 51/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.4973 - acc: 0.7500 - val_loss: 0.4303 - val_acc: 0.8421\n",
      "Epoch 52/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4877 - acc: 0.7750 - val_loss: 0.4570 - val_acc: 0.8246\n",
      "Epoch 53/250\n",
      "40/40 [==============================] - 22s 549ms/step - loss: 0.4335 - acc: 0.8208 - val_loss: 0.4759 - val_acc: 0.8070\n",
      "Epoch 54/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.5051 - acc: 0.7542 - val_loss: 0.5267 - val_acc: 0.7368\n",
      "Epoch 55/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.5401 - acc: 0.7250 - val_loss: 0.5491 - val_acc: 0.7193\n",
      "Epoch 56/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.5119 - acc: 0.7583 - val_loss: 0.4566 - val_acc: 0.8246\n",
      "Epoch 57/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4650 - acc: 0.8000 - val_loss: 0.5468 - val_acc: 0.7193\n",
      "Epoch 58/250\n",
      "40/40 [==============================] - 22s 549ms/step - loss: 0.5066 - acc: 0.7458 - val_loss: 0.4460 - val_acc: 0.8246\n",
      "Epoch 59/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.4972 - acc: 0.7833 - val_loss: 0.4456 - val_acc: 0.8246\n",
      "Epoch 60/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4671 - acc: 0.7875 - val_loss: 0.4683 - val_acc: 0.8246\n",
      "Epoch 61/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4766 - acc: 0.7583 - val_loss: 0.4407 - val_acc: 0.8246\n",
      "Epoch 62/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4514 - acc: 0.7917 - val_loss: 0.4200 - val_acc: 0.8596\n",
      "Epoch 63/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4687 - acc: 0.7625 - val_loss: 0.4232 - val_acc: 0.8421\n",
      "Epoch 64/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.5164 - acc: 0.7125 - val_loss: 0.4738 - val_acc: 0.8070\n",
      "Epoch 65/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.5107 - acc: 0.7667 - val_loss: 0.4460 - val_acc: 0.8246\n",
      "Epoch 66/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4950 - acc: 0.7833 - val_loss: 0.4643 - val_acc: 0.8246\n",
      "Epoch 67/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.5036 - acc: 0.7542 - val_loss: 0.4531 - val_acc: 0.8246\n",
      "Epoch 68/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.5211 - acc: 0.7292 - val_loss: 0.4839 - val_acc: 0.8070\n",
      "Epoch 69/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4828 - acc: 0.7542 - val_loss: 0.4270 - val_acc: 0.8246\n",
      "Epoch 70/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4796 - acc: 0.7792 - val_loss: 0.4937 - val_acc: 0.7895\n",
      "Epoch 71/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4966 - acc: 0.7583 - val_loss: 0.5365 - val_acc: 0.7544\n",
      "Epoch 72/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.4925 - acc: 0.7667 - val_loss: 0.5355 - val_acc: 0.7544\n",
      "Epoch 73/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.4807 - acc: 0.7708 - val_loss: 0.4297 - val_acc: 0.8421\n",
      "Epoch 74/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4469 - acc: 0.7833 - val_loss: 0.4264 - val_acc: 0.8421\n",
      "Epoch 75/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4825 - acc: 0.7792 - val_loss: 0.4502 - val_acc: 0.8421\n",
      "Epoch 76/250\n",
      "40/40 [==============================] - 22s 549ms/step - loss: 0.4838 - acc: 0.7625 - val_loss: 0.4579 - val_acc: 0.8246\n",
      "Epoch 77/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.5116 - acc: 0.7583 - val_loss: 0.4806 - val_acc: 0.8070\n",
      "Epoch 78/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.4448 - acc: 0.7958 - val_loss: 0.5221 - val_acc: 0.7544\n",
      "Epoch 79/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.4351 - acc: 0.8208 - val_loss: 0.4068 - val_acc: 0.8772\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 80/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.4911 - acc: 0.7417 - val_loss: 0.4742 - val_acc: 0.8070\n",
      "Epoch 81/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.3980 - acc: 0.8250 - val_loss: 0.4428 - val_acc: 0.8421\n",
      "Epoch 82/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.4850 - acc: 0.7417 - val_loss: 0.4117 - val_acc: 0.8596\n",
      "Epoch 83/250\n",
      "40/40 [==============================] - 23s 573ms/step - loss: 0.4800 - acc: 0.7792 - val_loss: 0.3826 - val_acc: 0.8596\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 84/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4512 - acc: 0.7875 - val_loss: 0.4239 - val_acc: 0.8421\n",
      "Epoch 85/250\n",
      "40/40 [==============================] - 23s 567ms/step - loss: 0.4564 - acc: 0.8000 - val_loss: 0.4650 - val_acc: 0.7895\n",
      "Epoch 86/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4736 - acc: 0.8250 - val_loss: 0.3875 - val_acc: 0.8596\n",
      "Epoch 87/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4830 - acc: 0.7625 - val_loss: 0.4034 - val_acc: 0.8596\n",
      "Epoch 88/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4964 - acc: 0.7750 - val_loss: 0.5711 - val_acc: 0.7368\n",
      "Epoch 89/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.4700 - acc: 0.7875 - val_loss: 0.4371 - val_acc: 0.8421\n",
      "Epoch 90/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4173 - acc: 0.8292 - val_loss: 0.4098 - val_acc: 0.8421\n",
      "Epoch 91/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4631 - acc: 0.7917 - val_loss: 0.5292 - val_acc: 0.7544\n",
      "Epoch 92/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4883 - acc: 0.7667 - val_loss: 0.4773 - val_acc: 0.8070\n",
      "Epoch 93/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.5131 - acc: 0.7292 - val_loss: 0.3966 - val_acc: 0.8596\n",
      "Epoch 94/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4738 - acc: 0.7458 - val_loss: 0.4769 - val_acc: 0.8070\n",
      "Epoch 95/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.5014 - acc: 0.7750 - val_loss: 0.4422 - val_acc: 0.8421\n",
      "Epoch 96/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4923 - acc: 0.7750 - val_loss: 0.4432 - val_acc: 0.8421\n",
      "Epoch 97/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.5026 - acc: 0.7458 - val_loss: 0.3815 - val_acc: 0.8596\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 98/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4782 - acc: 0.7833 - val_loss: 0.3784 - val_acc: 0.8596\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 99/250\n",
      "40/40 [==============================] - 22s 549ms/step - loss: 0.4633 - acc: 0.7958 - val_loss: 0.5042 - val_acc: 0.7719\n",
      "Epoch 100/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4547 - acc: 0.7833 - val_loss: 0.4625 - val_acc: 0.7895\n",
      "Epoch 101/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.4959 - acc: 0.7917 - val_loss: 0.4212 - val_acc: 0.8596\n",
      "Epoch 102/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.5247 - acc: 0.7083 - val_loss: 0.4212 - val_acc: 0.8596\n",
      "Epoch 103/250\n",
      "40/40 [==============================] - 22s 547ms/step - loss: 0.4077 - acc: 0.8208 - val_loss: 0.4188 - val_acc: 0.8596\n",
      "Epoch 104/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4271 - acc: 0.8333 - val_loss: 0.4233 - val_acc: 0.8421\n",
      "Epoch 105/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4845 - acc: 0.7750 - val_loss: 0.4525 - val_acc: 0.8421\n",
      "Epoch 106/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.4250 - acc: 0.7917 - val_loss: 0.4860 - val_acc: 0.7895\n",
      "Epoch 107/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.3945 - acc: 0.8125 - val_loss: 0.3863 - val_acc: 0.8772\n",
      "Epoch 108/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4431 - acc: 0.7958 - val_loss: 0.5570 - val_acc: 0.7193\n",
      "Epoch 109/250\n",
      "40/40 [==============================] - 22s 546ms/step - loss: 0.4522 - acc: 0.7833 - val_loss: 0.3975 - val_acc: 0.8596\n",
      "Epoch 110/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4818 - acc: 0.7583 - val_loss: 0.4476 - val_acc: 0.8246\n",
      "Epoch 111/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.4352 - acc: 0.7917 - val_loss: 0.5081 - val_acc: 0.7544\n",
      "Epoch 112/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4942 - acc: 0.7667 - val_loss: 0.4279 - val_acc: 0.8421\n",
      "Epoch 113/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4787 - acc: 0.7708 - val_loss: 0.4429 - val_acc: 0.8421\n",
      "Epoch 114/250\n",
      "40/40 [==============================] - 23s 568ms/step - loss: 0.4848 - acc: 0.7542 - val_loss: 0.4551 - val_acc: 0.8246\n",
      "Epoch 115/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4995 - acc: 0.7375 - val_loss: 0.3967 - val_acc: 0.8596\n",
      "Epoch 116/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4620 - acc: 0.8000 - val_loss: 0.4286 - val_acc: 0.8421\n",
      "Epoch 117/250\n",
      "40/40 [==============================] - 22s 545ms/step - loss: 0.4823 - acc: 0.7708 - val_loss: 0.4576 - val_acc: 0.8246\n",
      "Epoch 118/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4280 - acc: 0.8125 - val_loss: 0.4264 - val_acc: 0.8421\n",
      "Epoch 119/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.4536 - acc: 0.7875 - val_loss: 0.4637 - val_acc: 0.8246\n",
      "Epoch 120/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4916 - acc: 0.7542 - val_loss: 0.4222 - val_acc: 0.8596\n",
      "Epoch 121/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.4376 - acc: 0.8000 - val_loss: 0.4807 - val_acc: 0.8070\n",
      "Epoch 122/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.4241 - acc: 0.7792 - val_loss: 0.4372 - val_acc: 0.8421\n",
      "Epoch 123/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4395 - acc: 0.8000 - val_loss: 0.3953 - val_acc: 0.8596\n",
      "Epoch 124/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4682 - acc: 0.7792 - val_loss: 0.3994 - val_acc: 0.8596\n",
      "Epoch 125/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.4681 - acc: 0.7833 - val_loss: 0.4303 - val_acc: 0.8421\n",
      "Epoch 126/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4499 - acc: 0.8208 - val_loss: 0.4626 - val_acc: 0.8246\n",
      "Epoch 127/250\n",
      "40/40 [==============================] - 22s 545ms/step - loss: 0.4153 - acc: 0.8292 - val_loss: 0.5700 - val_acc: 0.7368\n",
      "Epoch 128/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.4549 - acc: 0.7875 - val_loss: 0.4122 - val_acc: 0.8421\n",
      "Epoch 129/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.4535 - acc: 0.7875 - val_loss: 0.4483 - val_acc: 0.8421\n",
      "Epoch 130/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4765 - acc: 0.7958 - val_loss: 0.4360 - val_acc: 0.8421\n",
      "Epoch 131/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.4655 - acc: 0.7708 - val_loss: 0.4298 - val_acc: 0.8421\n",
      "Epoch 132/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4480 - acc: 0.8167 - val_loss: 0.5229 - val_acc: 0.7544\n",
      "Epoch 133/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4345 - acc: 0.7833 - val_loss: 0.4386 - val_acc: 0.8421\n",
      "Epoch 134/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4555 - acc: 0.8083 - val_loss: 0.5522 - val_acc: 0.7544\n",
      "Epoch 135/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.3967 - acc: 0.8208 - val_loss: 0.3966 - val_acc: 0.8596\n",
      "Epoch 136/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4683 - acc: 0.7833 - val_loss: 0.5802 - val_acc: 0.7368\n",
      "Epoch 137/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.4145 - acc: 0.8000 - val_loss: 0.3732 - val_acc: 0.8772\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 138/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4107 - acc: 0.8125 - val_loss: 0.4094 - val_acc: 0.8596\n",
      "Epoch 139/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.4039 - acc: 0.8000 - val_loss: 0.4127 - val_acc: 0.8421\n",
      "Epoch 140/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4719 - acc: 0.7667 - val_loss: 0.3813 - val_acc: 0.8421\n",
      "Epoch 141/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4570 - acc: 0.7792 - val_loss: 0.3992 - val_acc: 0.8596\n",
      "Epoch 142/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.4204 - acc: 0.8000 - val_loss: 0.3934 - val_acc: 0.8421\n",
      "Epoch 143/250\n",
      "40/40 [==============================] - 22s 549ms/step - loss: 0.4122 - acc: 0.8000 - val_loss: 0.3687 - val_acc: 0.8421\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 144/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4292 - acc: 0.8000 - val_loss: 0.3909 - val_acc: 0.8596\n",
      "Epoch 145/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4598 - acc: 0.7667 - val_loss: 0.4264 - val_acc: 0.8421\n",
      "Epoch 146/250\n",
      "40/40 [==============================] - 23s 567ms/step - loss: 0.4153 - acc: 0.7958 - val_loss: 0.4163 - val_acc: 0.8421\n",
      "Epoch 147/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4676 - acc: 0.7833 - val_loss: 0.4539 - val_acc: 0.8246\n",
      "Epoch 148/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.4725 - acc: 0.7917 - val_loss: 0.4189 - val_acc: 0.8421\n",
      "Epoch 149/250\n",
      "40/40 [==============================] - 23s 568ms/step - loss: 0.4476 - acc: 0.7708 - val_loss: 0.3799 - val_acc: 0.8596\n",
      "Epoch 150/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4237 - acc: 0.8083 - val_loss: 0.3969 - val_acc: 0.8596\n",
      "Epoch 151/250\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.4427 - acc: 0.8083 - val_loss: 0.4040 - val_acc: 0.8596\n",
      "Epoch 152/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.3796 - acc: 0.8208 - val_loss: 0.4329 - val_acc: 0.8421\n",
      "Epoch 153/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3936 - acc: 0.8542 - val_loss: 0.3981 - val_acc: 0.8596\n",
      "Epoch 154/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4477 - acc: 0.8042 - val_loss: 0.5141 - val_acc: 0.7719\n",
      "Epoch 155/250\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.4278 - acc: 0.8167 - val_loss: 0.4453 - val_acc: 0.8070\n",
      "Epoch 156/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4888 - acc: 0.7500 - val_loss: 0.4168 - val_acc: 0.8246\n",
      "Epoch 157/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.4440 - acc: 0.8083 - val_loss: 0.3726 - val_acc: 0.8421\n",
      "Epoch 158/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.4179 - acc: 0.8083 - val_loss: 0.3894 - val_acc: 0.8596\n",
      "Epoch 159/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4503 - acc: 0.8042 - val_loss: 0.4078 - val_acc: 0.8596\n",
      "Epoch 160/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4442 - acc: 0.7750 - val_loss: 0.4221 - val_acc: 0.8421\n",
      "Epoch 161/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4335 - acc: 0.7958 - val_loss: 0.4530 - val_acc: 0.8246\n",
      "Epoch 162/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4319 - acc: 0.7833 - val_loss: 0.3882 - val_acc: 0.8421\n",
      "Epoch 163/250\n",
      "40/40 [==============================] - 22s 549ms/step - loss: 0.4364 - acc: 0.7958 - val_loss: 0.4086 - val_acc: 0.8596\n",
      "Epoch 164/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.3922 - acc: 0.8208 - val_loss: 0.3832 - val_acc: 0.8421\n",
      "Epoch 165/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4383 - acc: 0.7875 - val_loss: 0.3831 - val_acc: 0.8421\n",
      "Epoch 166/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.3988 - acc: 0.8000 - val_loss: 0.4338 - val_acc: 0.8421\n",
      "Epoch 167/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3861 - acc: 0.8292 - val_loss: 0.4317 - val_acc: 0.8421\n",
      "Epoch 168/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.3217 - acc: 0.8667 - val_loss: 0.4282 - val_acc: 0.8246\n",
      "Epoch 169/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3933 - acc: 0.8375 - val_loss: 0.4959 - val_acc: 0.8070\n",
      "Epoch 170/250\n",
      "40/40 [==============================] - 23s 573ms/step - loss: 0.3408 - acc: 0.8875 - val_loss: 0.3952 - val_acc: 0.8421\n",
      "Epoch 171/250\n",
      "40/40 [==============================] - 22s 545ms/step - loss: 0.3570 - acc: 0.8542 - val_loss: 0.3808 - val_acc: 0.8421\n",
      "Epoch 172/250\n",
      "40/40 [==============================] - 23s 565ms/step - loss: 0.4025 - acc: 0.8292 - val_loss: 0.4078 - val_acc: 0.8421\n",
      "Epoch 173/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.4276 - acc: 0.8083 - val_loss: 0.4158 - val_acc: 0.8421\n",
      "Epoch 174/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.4178 - acc: 0.8417 - val_loss: 0.4627 - val_acc: 0.8070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4559 - acc: 0.7667 - val_loss: 0.4191 - val_acc: 0.8421\n",
      "Epoch 176/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.3999 - acc: 0.8375 - val_loss: 0.4384 - val_acc: 0.8421\n",
      "Epoch 177/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4052 - acc: 0.8375 - val_loss: 0.4453 - val_acc: 0.8246\n",
      "Epoch 178/250\n",
      "40/40 [==============================] - 23s 570ms/step - loss: 0.4733 - acc: 0.7917 - val_loss: 0.4376 - val_acc: 0.8246\n",
      "Epoch 179/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.3731 - acc: 0.8292 - val_loss: 0.3921 - val_acc: 0.8596\n",
      "Epoch 180/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4270 - acc: 0.7875 - val_loss: 0.4604 - val_acc: 0.8070\n",
      "Epoch 181/250\n",
      "40/40 [==============================] - 23s 567ms/step - loss: 0.4263 - acc: 0.8208 - val_loss: 0.4079 - val_acc: 0.8596\n",
      "Epoch 182/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.4546 - acc: 0.7875 - val_loss: 0.5239 - val_acc: 0.7719\n",
      "Epoch 183/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4140 - acc: 0.8083 - val_loss: 0.3953 - val_acc: 0.8596\n",
      "Epoch 184/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.3881 - acc: 0.8500 - val_loss: 0.4694 - val_acc: 0.8070\n",
      "Epoch 185/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.4314 - acc: 0.7833 - val_loss: 0.4279 - val_acc: 0.8421\n",
      "Epoch 186/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.4086 - acc: 0.8292 - val_loss: 0.4245 - val_acc: 0.8596\n",
      "Epoch 187/250\n",
      "40/40 [==============================] - 22s 543ms/step - loss: 0.3905 - acc: 0.8417 - val_loss: 0.4487 - val_acc: 0.8246\n",
      "Epoch 188/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4212 - acc: 0.7958 - val_loss: 0.4424 - val_acc: 0.8246\n",
      "Epoch 189/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4205 - acc: 0.8000 - val_loss: 0.4036 - val_acc: 0.8596\n",
      "Epoch 190/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.3922 - acc: 0.8125 - val_loss: 0.4088 - val_acc: 0.8596\n",
      "Epoch 191/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4403 - acc: 0.7708 - val_loss: 0.3996 - val_acc: 0.8596\n",
      "Epoch 192/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.3734 - acc: 0.8375 - val_loss: 0.4355 - val_acc: 0.8246\n",
      "Epoch 193/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.3213 - acc: 0.8667 - val_loss: 0.3773 - val_acc: 0.8421\n",
      "Epoch 194/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.3869 - acc: 0.8292 - val_loss: 0.4019 - val_acc: 0.8596\n",
      "Epoch 195/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4306 - acc: 0.8208 - val_loss: 0.4184 - val_acc: 0.8246\n",
      "Epoch 196/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.4143 - acc: 0.8000 - val_loss: 0.3953 - val_acc: 0.8596\n",
      "Epoch 197/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.4096 - acc: 0.7958 - val_loss: 0.4086 - val_acc: 0.8596\n",
      "Epoch 198/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.4505 - acc: 0.7917 - val_loss: 0.5302 - val_acc: 0.7895\n",
      "Epoch 199/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.3488 - acc: 0.8583 - val_loss: 0.3842 - val_acc: 0.8596\n",
      "Epoch 200/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.3694 - acc: 0.8500 - val_loss: 0.4144 - val_acc: 0.8421\n",
      "Epoch 201/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.3774 - acc: 0.8125 - val_loss: 0.4527 - val_acc: 0.8070\n",
      "Epoch 202/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.3845 - acc: 0.8083 - val_loss: 0.5275 - val_acc: 0.7895\n",
      "Epoch 203/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.3970 - acc: 0.8125 - val_loss: 0.5863 - val_acc: 0.7368\n",
      "Epoch 204/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.3722 - acc: 0.8500 - val_loss: 0.3862 - val_acc: 0.8421\n",
      "Epoch 205/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.3938 - acc: 0.8333 - val_loss: 0.4121 - val_acc: 0.8246\n",
      "Epoch 206/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3775 - acc: 0.8625 - val_loss: 0.3814 - val_acc: 0.8421\n",
      "Epoch 207/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4060 - acc: 0.7917 - val_loss: 0.5325 - val_acc: 0.7895\n",
      "Epoch 208/250\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.3724 - acc: 0.8250 - val_loss: 0.4024 - val_acc: 0.8421\n",
      "Epoch 209/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4293 - acc: 0.8167 - val_loss: 0.4213 - val_acc: 0.8596\n",
      "Epoch 210/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.3481 - acc: 0.8417 - val_loss: 0.4465 - val_acc: 0.8246\n",
      "Epoch 211/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.4140 - acc: 0.8042 - val_loss: 0.4507 - val_acc: 0.8246\n",
      "Epoch 212/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.3036 - acc: 0.8875 - val_loss: 0.4208 - val_acc: 0.8246\n",
      "Epoch 213/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.4215 - acc: 0.8208 - val_loss: 0.3962 - val_acc: 0.8421\n",
      "Epoch 214/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3571 - acc: 0.8333 - val_loss: 0.4014 - val_acc: 0.8596\n",
      "Epoch 215/250\n",
      "40/40 [==============================] - 23s 563ms/step - loss: 0.3757 - acc: 0.8333 - val_loss: 0.4328 - val_acc: 0.8246\n",
      "Epoch 216/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.2908 - acc: 0.9042 - val_loss: 0.4529 - val_acc: 0.8246\n",
      "Epoch 217/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.3914 - acc: 0.8042 - val_loss: 0.4406 - val_acc: 0.8246\n",
      "Epoch 218/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.3543 - acc: 0.8417 - val_loss: 0.4144 - val_acc: 0.8246\n",
      "Epoch 219/250\n",
      "40/40 [==============================] - 23s 570ms/step - loss: 0.3676 - acc: 0.8292 - val_loss: 0.4023 - val_acc: 0.8596\n",
      "Epoch 220/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.3436 - acc: 0.8333 - val_loss: 0.4302 - val_acc: 0.8246\n",
      "Epoch 221/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.3698 - acc: 0.8292 - val_loss: 0.3764 - val_acc: 0.8596\n",
      "Epoch 222/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.3912 - acc: 0.8125 - val_loss: 0.4135 - val_acc: 0.8596\n",
      "Epoch 223/250\n",
      "40/40 [==============================] - 22s 551ms/step - loss: 0.3799 - acc: 0.8250 - val_loss: 0.3838 - val_acc: 0.8772\n",
      "Epoch 224/250\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.3818 - acc: 0.8167 - val_loss: 0.3692 - val_acc: 0.8246\n",
      "Epoch 225/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3899 - acc: 0.8083 - val_loss: 0.3854 - val_acc: 0.8772\n",
      "Epoch 226/250\n",
      "40/40 [==============================] - 22s 545ms/step - loss: 0.3572 - acc: 0.8125 - val_loss: 0.4058 - val_acc: 0.8421\n",
      "Epoch 227/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.3541 - acc: 0.8458 - val_loss: 0.4271 - val_acc: 0.8246\n",
      "Epoch 228/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.3451 - acc: 0.8542 - val_loss: 0.4227 - val_acc: 0.8246\n",
      "Epoch 229/250\n",
      "40/40 [==============================] - 22s 557ms/step - loss: 0.3180 - acc: 0.8542 - val_loss: 0.4331 - val_acc: 0.8246\n",
      "Epoch 230/250\n",
      "40/40 [==============================] - 22s 560ms/step - loss: 0.4109 - acc: 0.8167 - val_loss: 0.3635 - val_acc: 0.8421\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 231/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.3796 - acc: 0.8542 - val_loss: 0.4233 - val_acc: 0.8596\n",
      "Epoch 232/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4369 - acc: 0.8125 - val_loss: 0.5526 - val_acc: 0.7895\n",
      "Epoch 233/250\n",
      "40/40 [==============================] - 22s 542ms/step - loss: 0.3144 - acc: 0.8750 - val_loss: 0.4363 - val_acc: 0.8246\n",
      "Epoch 234/250\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.4133 - acc: 0.8042 - val_loss: 0.4015 - val_acc: 0.8421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.3671 - acc: 0.8583 - val_loss: 0.4927 - val_acc: 0.7895\n",
      "Epoch 236/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.4167 - acc: 0.8250 - val_loss: 0.3684 - val_acc: 0.8421\n",
      "Epoch 237/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.3730 - acc: 0.8250 - val_loss: 0.4779 - val_acc: 0.7895\n",
      "Epoch 238/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.3641 - acc: 0.8458 - val_loss: 0.3947 - val_acc: 0.8246\n",
      "Epoch 239/250\n",
      "40/40 [==============================] - 22s 553ms/step - loss: 0.3598 - acc: 0.8750 - val_loss: 0.4693 - val_acc: 0.7895\n",
      "Epoch 240/250\n",
      "40/40 [==============================] - 22s 556ms/step - loss: 0.3772 - acc: 0.8375 - val_loss: 0.4424 - val_acc: 0.8246\n",
      "Epoch 241/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.3965 - acc: 0.8292 - val_loss: 0.3939 - val_acc: 0.8596\n",
      "Epoch 242/250\n",
      "40/40 [==============================] - 22s 559ms/step - loss: 0.3565 - acc: 0.8458 - val_loss: 0.4133 - val_acc: 0.8421\n",
      "Epoch 243/250\n",
      "40/40 [==============================] - 22s 552ms/step - loss: 0.3435 - acc: 0.8667 - val_loss: 0.5236 - val_acc: 0.8070\n",
      "Epoch 244/250\n",
      "40/40 [==============================] - 23s 567ms/step - loss: 0.3816 - acc: 0.8083 - val_loss: 0.3893 - val_acc: 0.8421\n",
      "Epoch 245/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.3555 - acc: 0.8333 - val_loss: 0.4217 - val_acc: 0.8421\n",
      "Epoch 246/250\n",
      "40/40 [==============================] - 22s 554ms/step - loss: 0.3457 - acc: 0.8708 - val_loss: 0.3680 - val_acc: 0.8421\n",
      "Epoch 247/250\n",
      "40/40 [==============================] - 22s 548ms/step - loss: 0.3848 - acc: 0.8500 - val_loss: 0.4009 - val_acc: 0.8596\n",
      "Epoch 248/250\n",
      "40/40 [==============================] - 22s 550ms/step - loss: 0.3231 - acc: 0.8667 - val_loss: 0.3585 - val_acc: 0.8246\n",
      "Saving to ./results_1st/1st-step_fold_2.h5\n",
      "Epoch 249/250\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.4183 - acc: 0.8042 - val_loss: 0.4101 - val_acc: 0.8596\n",
      "Epoch 250/250\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.3253 - acc: 0.8750 - val_loss: 0.4695 - val_acc: 0.7895\n",
      "Fold 3\n",
      "PatchGenerator detected: 229 patch samples.\n",
      "- Cysts: 67 cases\n",
      "- Tumors: 126 cases\n",
      "- Fibroadenoma: 36 cases\n",
      "PatchSequence detected: 69 patch samples.\n",
      "- Cysts: 22 cases\n",
      "- Tumors: 40 cases\n",
      "- Fibroadenoma: 7 cases\n",
      "Epoch 1/250\n",
      "38/38 [==============================] - 30s 790ms/step - loss: 0.6931 - acc: 0.4825 - val_loss: 0.6935 - val_acc: 0.3188\n",
      "Epoch 2/250\n",
      "38/38 [==============================] - 22s 588ms/step - loss: 0.6929 - acc: 0.5000 - val_loss: 0.6935 - val_acc: 0.3188\n",
      "Epoch 3/250\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.6925 - acc: 0.5263 - val_loss: 0.6931 - val_acc: 0.4783\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 4/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.6916 - acc: 0.6798 - val_loss: 0.6925 - val_acc: 0.5507\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 5/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.6891 - acc: 0.6140 - val_loss: 0.6922 - val_acc: 0.5362\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 6/250\n",
      "38/38 [==============================] - 22s 577ms/step - loss: 0.6830 - acc: 0.7368 - val_loss: 0.6842 - val_acc: 0.6667\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 7/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.6768 - acc: 0.7018 - val_loss: 0.6938 - val_acc: 0.4783\n",
      "Epoch 8/250\n",
      "38/38 [==============================] - 22s 572ms/step - loss: 0.6668 - acc: 0.7061 - val_loss: 0.6816 - val_acc: 0.5507\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 9/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.6417 - acc: 0.7456 - val_loss: 0.6453 - val_acc: 0.7681\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 10/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.6240 - acc: 0.7500 - val_loss: 0.6433 - val_acc: 0.6377\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 11/250\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 0.6277 - acc: 0.6711 - val_loss: 0.6186 - val_acc: 0.6812\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 12/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.5831 - acc: 0.7675 - val_loss: 0.5923 - val_acc: 0.7681\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 13/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.5862 - acc: 0.7061 - val_loss: 0.6190 - val_acc: 0.6667\n",
      "Epoch 14/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.5362 - acc: 0.7851 - val_loss: 0.6647 - val_acc: 0.5942\n",
      "Epoch 15/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.5143 - acc: 0.8158 - val_loss: 0.5411 - val_acc: 0.7536\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 16/250\n",
      "38/38 [==============================] - 22s 585ms/step - loss: 0.5292 - acc: 0.7544 - val_loss: 0.5747 - val_acc: 0.6522\n",
      "Epoch 17/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.5065 - acc: 0.8070 - val_loss: 0.5279 - val_acc: 0.7391\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 18/250\n",
      "38/38 [==============================] - 22s 579ms/step - loss: 0.5298 - acc: 0.7982 - val_loss: 0.5476 - val_acc: 0.6957\n",
      "Epoch 19/250\n",
      "38/38 [==============================] - 22s 569ms/step - loss: 0.4991 - acc: 0.7632 - val_loss: 0.5689 - val_acc: 0.6667\n",
      "Epoch 20/250\n",
      "38/38 [==============================] - 22s 592ms/step - loss: 0.5125 - acc: 0.7544 - val_loss: 0.5141 - val_acc: 0.7536\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 21/250\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.4881 - acc: 0.7982 - val_loss: 0.5497 - val_acc: 0.6812\n",
      "Epoch 22/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.5145 - acc: 0.7588 - val_loss: 0.5734 - val_acc: 0.6667\n",
      "Epoch 23/250\n",
      "38/38 [==============================] - 21s 565ms/step - loss: 0.5304 - acc: 0.7500 - val_loss: 0.5415 - val_acc: 0.6812\n",
      "Epoch 24/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.5136 - acc: 0.7325 - val_loss: 0.5629 - val_acc: 0.6812\n",
      "Epoch 25/250\n",
      "38/38 [==============================] - 22s 580ms/step - loss: 0.4505 - acc: 0.8289 - val_loss: 0.5277 - val_acc: 0.7101\n",
      "Epoch 26/250\n",
      "38/38 [==============================] - 22s 579ms/step - loss: 0.5037 - acc: 0.7982 - val_loss: 0.5196 - val_acc: 0.7391\n",
      "Epoch 27/250\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.4829 - acc: 0.7675 - val_loss: 0.5572 - val_acc: 0.6812\n",
      "Epoch 28/250\n",
      "38/38 [==============================] - 22s 579ms/step - loss: 0.4680 - acc: 0.7632 - val_loss: 0.5092 - val_acc: 0.7536\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 29/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.4418 - acc: 0.8202 - val_loss: 0.5586 - val_acc: 0.6812\n",
      "Epoch 30/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.4517 - acc: 0.8070 - val_loss: 0.5447 - val_acc: 0.6812\n",
      "Epoch 31/250\n",
      "38/38 [==============================] - 22s 587ms/step - loss: 0.4905 - acc: 0.7719 - val_loss: 0.5040 - val_acc: 0.7536\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 32/250\n",
      "38/38 [==============================] - 23s 593ms/step - loss: 0.4386 - acc: 0.8289 - val_loss: 0.4948 - val_acc: 0.7681\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 33/250\n",
      "38/38 [==============================] - 22s 571ms/step - loss: 0.4546 - acc: 0.7982 - val_loss: 0.6709 - val_acc: 0.6232\n",
      "Epoch 34/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.4480 - acc: 0.7675 - val_loss: 0.4877 - val_acc: 0.7536\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 35/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.4280 - acc: 0.8377 - val_loss: 0.4919 - val_acc: 0.7826\n",
      "Epoch 36/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.4075 - acc: 0.8289 - val_loss: 0.4891 - val_acc: 0.7536\n",
      "Epoch 37/250\n",
      "38/38 [==============================] - 22s 587ms/step - loss: 0.4474 - acc: 0.7719 - val_loss: 0.5113 - val_acc: 0.7391\n",
      "Epoch 38/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.4310 - acc: 0.8202 - val_loss: 0.4861 - val_acc: 0.7681\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 39/250\n",
      "38/38 [==============================] - 23s 594ms/step - loss: 0.4792 - acc: 0.7939 - val_loss: 0.5234 - val_acc: 0.6957\n",
      "Epoch 40/250\n",
      "38/38 [==============================] - 22s 581ms/step - loss: 0.5016 - acc: 0.7807 - val_loss: 0.5149 - val_acc: 0.7391\n",
      "Epoch 41/250\n",
      "38/38 [==============================] - 22s 580ms/step - loss: 0.4859 - acc: 0.7632 - val_loss: 0.4864 - val_acc: 0.7536\n",
      "Epoch 42/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.4994 - acc: 0.7851 - val_loss: 0.5128 - val_acc: 0.7391\n",
      "Epoch 43/250\n",
      "38/38 [==============================] - 21s 563ms/step - loss: 0.5110 - acc: 0.7544 - val_loss: 0.5288 - val_acc: 0.6957\n",
      "Epoch 44/250\n",
      "38/38 [==============================] - 22s 581ms/step - loss: 0.4105 - acc: 0.8377 - val_loss: 0.4823 - val_acc: 0.7536\n",
      "Saving to ./results_1st/1st-step_fold_3.h5\n",
      "Epoch 45/250\n",
      "38/38 [==============================] - 22s 577ms/step - loss: 0.4492 - acc: 0.8070 - val_loss: 0.5543 - val_acc: 0.6957\n",
      "Epoch 46/250\n",
      "38/38 [==============================] - 22s 580ms/step - loss: 0.5209 - acc: 0.7588 - val_loss: 0.5173 - val_acc: 0.7391\n",
      "Epoch 47/250\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.4285 - acc: 0.8377 - val_loss: 0.5796 - val_acc: 0.6812\n",
      "Epoch 48/250\n",
      "38/38 [==============================] - 22s 572ms/step - loss: 0.3847 - acc: 0.8289 - val_loss: 0.5355 - val_acc: 0.6957\n",
      "Epoch 49/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.4435 - acc: 0.8289 - val_loss: 0.4907 - val_acc: 0.7536\n",
      "Epoch 50/250\n",
      "38/38 [==============================] - 22s 577ms/step - loss: 0.5020 - acc: 0.7675 - val_loss: 0.4955 - val_acc: 0.7681\n",
      "Epoch 51/250\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.4450 - acc: 0.7675 - val_loss: 0.5008 - val_acc: 0.7391\n",
      "Epoch 52/250\n",
      "38/38 [==============================] - 22s 586ms/step - loss: 0.3872 - acc: 0.8684 - val_loss: 0.5395 - val_acc: 0.6812\n",
      "Epoch 53/250\n",
      "38/38 [==============================] - 22s 571ms/step - loss: 0.4682 - acc: 0.7763 - val_loss: 0.4977 - val_acc: 0.7681\n",
      "Epoch 54/250\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.4233 - acc: 0.8070 - val_loss: 0.4932 - val_acc: 0.7536\n",
      "Epoch 55/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.3513 - acc: 0.8860 - val_loss: 0.4995 - val_acc: 0.7826\n",
      "Epoch 56/250\n",
      "38/38 [==============================] - 21s 559ms/step - loss: 0.3740 - acc: 0.8421 - val_loss: 0.5166 - val_acc: 0.7391\n",
      "Epoch 57/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.4336 - acc: 0.7807 - val_loss: 0.4879 - val_acc: 0.7536\n",
      "Epoch 58/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.4682 - acc: 0.7632 - val_loss: 0.4942 - val_acc: 0.7536\n",
      "Epoch 59/250\n",
      "38/38 [==============================] - 21s 563ms/step - loss: 0.4292 - acc: 0.8333 - val_loss: 0.5473 - val_acc: 0.6667\n",
      "Epoch 60/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.4350 - acc: 0.7982 - val_loss: 0.4845 - val_acc: 0.7681\n",
      "Epoch 61/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.4298 - acc: 0.8070 - val_loss: 0.5251 - val_acc: 0.7101\n",
      "Epoch 62/250\n",
      "38/38 [==============================] - 22s 580ms/step - loss: 0.3886 - acc: 0.8640 - val_loss: 0.5247 - val_acc: 0.7246\n",
      "Epoch 63/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.3763 - acc: 0.8596 - val_loss: 0.5204 - val_acc: 0.7246\n",
      "Epoch 64/250\n",
      "38/38 [==============================] - 22s 585ms/step - loss: 0.3960 - acc: 0.8377 - val_loss: 0.5295 - val_acc: 0.7101\n",
      "Epoch 65/250\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.4364 - acc: 0.8114 - val_loss: 0.5238 - val_acc: 0.7246\n",
      "Epoch 66/250\n",
      "38/38 [==============================] - 21s 564ms/step - loss: 0.4065 - acc: 0.8246 - val_loss: 0.5198 - val_acc: 0.7536\n",
      "Epoch 67/250\n",
      "38/38 [==============================] - 22s 586ms/step - loss: 0.4457 - acc: 0.7982 - val_loss: 0.5159 - val_acc: 0.7391\n",
      "Epoch 68/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.3907 - acc: 0.8246 - val_loss: 0.5341 - val_acc: 0.6957\n",
      "Epoch 69/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.3950 - acc: 0.8289 - val_loss: 0.5151 - val_acc: 0.7536\n",
      "Epoch 70/250\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.3925 - acc: 0.8246 - val_loss: 0.5427 - val_acc: 0.7101\n",
      "Epoch 71/250\n",
      "38/38 [==============================] - 22s 581ms/step - loss: 0.4002 - acc: 0.8640 - val_loss: 0.5397 - val_acc: 0.7101\n",
      "Epoch 72/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.5377 - acc: 0.7544 - val_loss: 0.4909 - val_acc: 0.7536\n",
      "Epoch 73/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.4513 - acc: 0.7982 - val_loss: 0.5368 - val_acc: 0.6957\n",
      "Epoch 74/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.4866 - acc: 0.7982 - val_loss: 0.5000 - val_acc: 0.7536\n",
      "Epoch 75/250\n",
      "38/38 [==============================] - 22s 572ms/step - loss: 0.3841 - acc: 0.8553 - val_loss: 0.5162 - val_acc: 0.7246\n",
      "Epoch 76/250\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.3608 - acc: 0.8553 - val_loss: 0.5057 - val_acc: 0.7391\n",
      "Epoch 77/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.3885 - acc: 0.8640 - val_loss: 0.5160 - val_acc: 0.7536\n",
      "Epoch 78/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.4131 - acc: 0.8026 - val_loss: 0.5693 - val_acc: 0.6667\n",
      "Epoch 79/250\n",
      "38/38 [==============================] - 22s 566ms/step - loss: 0.3912 - acc: 0.8421 - val_loss: 0.5039 - val_acc: 0.7391\n",
      "Epoch 80/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.3218 - acc: 0.8816 - val_loss: 0.5960 - val_acc: 0.6812\n",
      "Epoch 81/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.3945 - acc: 0.8333 - val_loss: 0.5171 - val_acc: 0.7536\n",
      "Epoch 82/250\n",
      "38/38 [==============================] - 22s 589ms/step - loss: 0.3639 - acc: 0.8728 - val_loss: 0.5376 - val_acc: 0.6957\n",
      "Epoch 83/250\n",
      "38/38 [==============================] - 22s 572ms/step - loss: 0.3943 - acc: 0.8377 - val_loss: 0.5144 - val_acc: 0.7536\n",
      "Epoch 84/250\n",
      "38/38 [==============================] - 22s 579ms/step - loss: 0.4082 - acc: 0.8114 - val_loss: 0.4987 - val_acc: 0.7391\n",
      "Epoch 85/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.3685 - acc: 0.8421 - val_loss: 0.5167 - val_acc: 0.7391\n",
      "Epoch 86/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.3595 - acc: 0.8289 - val_loss: 0.5122 - val_acc: 0.7391\n",
      "Epoch 87/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.4428 - acc: 0.7939 - val_loss: 0.5044 - val_acc: 0.7391\n",
      "Epoch 88/250\n",
      "38/38 [==============================] - 22s 581ms/step - loss: 0.3725 - acc: 0.8509 - val_loss: 0.5410 - val_acc: 0.6957\n",
      "Epoch 89/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.4009 - acc: 0.8246 - val_loss: 0.6008 - val_acc: 0.6812\n",
      "Epoch 90/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.4054 - acc: 0.8377 - val_loss: 0.5305 - val_acc: 0.7246\n",
      "Epoch 91/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.3331 - acc: 0.8991 - val_loss: 0.5156 - val_acc: 0.7391\n",
      "Epoch 92/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.3778 - acc: 0.8421 - val_loss: 0.5519 - val_acc: 0.6812\n",
      "Epoch 93/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.3851 - acc: 0.8596 - val_loss: 0.5312 - val_acc: 0.7536\n",
      "Epoch 94/250\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.4807 - acc: 0.7895 - val_loss: 0.5989 - val_acc: 0.6812\n",
      "Epoch 95/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.3797 - acc: 0.8553 - val_loss: 0.5121 - val_acc: 0.7391\n",
      "Epoch 96/250\n",
      "38/38 [==============================] - 22s 581ms/step - loss: 0.3905 - acc: 0.8421 - val_loss: 0.5096 - val_acc: 0.7536\n",
      "Epoch 97/250\n",
      "38/38 [==============================] - 22s 572ms/step - loss: 0.4563 - acc: 0.8333 - val_loss: 0.5050 - val_acc: 0.7391\n",
      "Epoch 98/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 22s 586ms/step - loss: 0.3798 - acc: 0.8728 - val_loss: 0.5296 - val_acc: 0.7391\n",
      "Epoch 99/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.4135 - acc: 0.8421 - val_loss: 0.5044 - val_acc: 0.7391\n",
      "Epoch 100/250\n",
      "38/38 [==============================] - 22s 590ms/step - loss: 0.3968 - acc: 0.8202 - val_loss: 0.5364 - val_acc: 0.7101\n",
      "Epoch 101/250\n",
      "38/38 [==============================] - 22s 569ms/step - loss: 0.4909 - acc: 0.7719 - val_loss: 0.5489 - val_acc: 0.6667\n",
      "Epoch 102/250\n",
      "38/38 [==============================] - 22s 589ms/step - loss: 0.3133 - acc: 0.8904 - val_loss: 0.5426 - val_acc: 0.6957\n",
      "Epoch 103/250\n",
      "38/38 [==============================] - 22s 579ms/step - loss: 0.3774 - acc: 0.8377 - val_loss: 0.5047 - val_acc: 0.7391\n",
      "Epoch 104/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.3529 - acc: 0.8465 - val_loss: 0.5458 - val_acc: 0.6957\n",
      "Epoch 105/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.4503 - acc: 0.7939 - val_loss: 0.5305 - val_acc: 0.7101\n",
      "Epoch 106/250\n",
      "38/38 [==============================] - 22s 573ms/step - loss: 0.3560 - acc: 0.8509 - val_loss: 0.5239 - val_acc: 0.7246\n",
      "Epoch 107/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.3795 - acc: 0.8333 - val_loss: 0.5740 - val_acc: 0.6812\n",
      "Epoch 108/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.4149 - acc: 0.8289 - val_loss: 0.5296 - val_acc: 0.7246\n",
      "Epoch 109/250\n",
      "38/38 [==============================] - 23s 595ms/step - loss: 0.3513 - acc: 0.8684 - val_loss: 0.5533 - val_acc: 0.6812\n",
      "Epoch 110/250\n",
      "38/38 [==============================] - 22s 580ms/step - loss: 0.4044 - acc: 0.8246 - val_loss: 0.5505 - val_acc: 0.6957\n",
      "Epoch 111/250\n",
      "38/38 [==============================] - 21s 558ms/step - loss: 0.4400 - acc: 0.8333 - val_loss: 0.6044 - val_acc: 0.6957\n",
      "Epoch 112/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.4139 - acc: 0.8289 - val_loss: 0.5077 - val_acc: 0.7391\n",
      "Epoch 113/250\n",
      "38/38 [==============================] - 22s 577ms/step - loss: 0.4131 - acc: 0.8289 - val_loss: 0.5071 - val_acc: 0.7536\n",
      "Epoch 114/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.4178 - acc: 0.8553 - val_loss: 0.5131 - val_acc: 0.7536\n",
      "Epoch 115/250\n",
      "38/38 [==============================] - 22s 583ms/step - loss: 0.3510 - acc: 0.8904 - val_loss: 0.5226 - val_acc: 0.7391\n",
      "Epoch 116/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.4721 - acc: 0.7500 - val_loss: 0.5375 - val_acc: 0.7101\n",
      "Epoch 117/250\n",
      "38/38 [==============================] - 22s 576ms/step - loss: 0.3873 - acc: 0.8465 - val_loss: 0.5489 - val_acc: 0.6957\n",
      "Epoch 118/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.3871 - acc: 0.8377 - val_loss: 0.6133 - val_acc: 0.6812\n",
      "Epoch 119/250\n",
      "38/38 [==============================] - 22s 574ms/step - loss: 0.4361 - acc: 0.8070 - val_loss: 0.5108 - val_acc: 0.7391\n",
      "Epoch 120/250\n",
      "38/38 [==============================] - 22s 567ms/step - loss: 0.3663 - acc: 0.8333 - val_loss: 0.5384 - val_acc: 0.7246\n",
      "Epoch 121/250\n",
      "38/38 [==============================] - 21s 566ms/step - loss: 0.3303 - acc: 0.8728 - val_loss: 0.5248 - val_acc: 0.7391\n",
      "Epoch 122/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.4495 - acc: 0.7895 - val_loss: 0.5157 - val_acc: 0.7391\n",
      "Epoch 123/250\n",
      "38/38 [==============================] - 22s 581ms/step - loss: 0.3704 - acc: 0.8333 - val_loss: 0.5223 - val_acc: 0.7391\n",
      "Epoch 124/250\n",
      "38/38 [==============================] - 22s 578ms/step - loss: 0.4374 - acc: 0.8289 - val_loss: 0.5133 - val_acc: 0.7391\n",
      "Epoch 125/250\n",
      "38/38 [==============================] - 22s 575ms/step - loss: 0.3335 - acc: 0.8553 - val_loss: 0.5133 - val_acc: 0.7391\n",
      "Epoch 126/250\n",
      "38/38 [==============================] - 22s 584ms/step - loss: 0.4149 - acc: 0.8333 - val_loss: 0.5299 - val_acc: 0.7246\n",
      "Epoch 127/250\n",
      "38/38 [==============================] - 22s 571ms/step - loss: 0.3476 - acc: 0.8553 - val_loss: 0.5931 - val_acc: 0.6957\n",
      "Epoch 128/250\n",
      "38/38 [==============================] - 22s 568ms/step - loss: 0.3746 - acc: 0.8465 - val_loss: 0.5146 - val_acc: 0.7391\n",
      "Epoch 129/250\n",
      "38/38 [==============================] - 22s 567ms/step - loss: 0.3273 - acc: 0.8947 - val_loss: 0.5139 - val_acc: 0.7391\n",
      "Epoch 130/250\n",
      "38/38 [==============================] - 22s 582ms/step - loss: 0.4519 - acc: 0.8070 - val_loss: 0.5640 - val_acc: 0.6667\n",
      "Epoch 131/250\n",
      "38/38 [==============================] - 22s 570ms/step - loss: 0.4963 - acc: 0.7412 - val_loss: 0.5085 - val_acc: 0.7391\n",
      "Epoch 132/250\n",
      "38/38 [==============================] - 22s 586ms/step - loss: 0.3629 - acc: 0.8728 - val_loss: 0.5274 - val_acc: 0.7101\n",
      "Epoch 133/250\n",
      "38/38 [==============================] - 22s 566ms/step - loss: 0.3010 - acc: 0.8772 - val_loss: 0.5174 - val_acc: 0.7536\n",
      "Epoch 134/250\n",
      "38/38 [==============================] - 22s 587ms/step - loss: 0.4071 - acc: 0.8333 - val_loss: 0.5778 - val_acc: 0.6812\n",
      "Epoch 135/250\n",
      "25/38 [==================>...........] - ETA: 4s - loss: 0.4708 - acc: 0.8133"
     ]
    }
   ],
   "source": [
    "train_model_1st()\n",
    "#train_model_2nd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model_2nd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
